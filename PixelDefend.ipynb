{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256084fa",
   "metadata": {},
   "source": [
    "**This notebook focuses on the effectiveness of PixelDefend against adversarial attacks on the MNIST and MARVEL datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929cdf42",
   "metadata": {},
   "source": [
    "## **Section 0 - Setting Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbf7b5",
   "metadata": {},
   "source": [
    "### **Load prerequisites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d608e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, Layer\n",
    "\n",
    "from keras_radam import RAdam\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from art import config\n",
    "from art.attacks.evasion import FastGradientMethod, DeepFool, ProjectedGradientDescent, SaliencyMapMethod, CarliniL2Method, NewtonFool, BasicIterativeMethod\n",
    "from art.defences.preprocessor import PixelDefend\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.estimators.classification import KerasClassifier, TensorFlowV2Classifier\n",
    "from art.utils import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86a2d2",
   "metadata": {},
   "source": [
    "## Build a PixelCNN for PixelDefend to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8cef786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a small Pixel CNN++ model to train on MNIST.\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "# tf.enable_v2_behavior()\n",
    "\n",
    "# Load MNIST from tensorflow_datasets\n",
    "data = tfds.load('mnist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29f02ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "n_residual_blocks = 5\n",
    "# The data, split between train and test sets\n",
    "(x, _), (y, _) = keras.datasets.mnist.load_data()\n",
    "x, y = x[:1000], y[:1000]\n",
    "# Concatenate all of the images together\n",
    "data = np.concatenate((x, y), axis=0)\n",
    "# Round all pixel values less than 33% of the max 256 value to 0\n",
    "# anything above this value gets rounded up to 1 so that all values are either\n",
    "# 0 or 1\n",
    "data = np.where(data < (0.33 * 256), 0, 1)\n",
    "data = data.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1516b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first layer is the PixelCNN layer. This layer simply\n",
    "# builds on the 2D convolutional layer, but includes masking.\n",
    "class PixelConvLayer(Layer):\n",
    "    def __init__(self, mask_type, **kwargs):\n",
    "        super(PixelConvLayer, self).__init__()\n",
    "        self.mask_type = mask_type\n",
    "        self.conv = Conv2D(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Build the conv2d layer to initialize kernel variables\n",
    "        self.conv.build(input_shape)\n",
    "        # Use the initialized kernel to create the mask\n",
    "        kernel_shape = self.conv.kernel.get_shape()\n",
    "        self.mask = np.zeros(shape=kernel_shape)\n",
    "        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
    "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
    "        if self.mask_type == \"B\":\n",
    "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
    "        return self.conv(inputs)\n",
    "\n",
    "\n",
    "# Next, we build our residual block layer.\n",
    "# This is just a normal residual block, but based on the PixelConvLayer.\n",
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.conv1 = Conv2D(\n",
    "            filters=filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "        self.pixel_conv = PixelConvLayer(\n",
    "            mask_type=\"B\",\n",
    "            filters=filters // 2,\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.conv2 = Conv2D(\n",
    "            filters=filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pixel_conv(x)\n",
    "        x = self.conv2(x)\n",
    "        return tf.keras.layers.add([inputs, x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "add11aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_8 (PixelCon (None, 28, 28, 128)       6400      \n",
      "_________________________________________________________________\n",
      "residual_block_5 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_6 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_7 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_8 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_9 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_14 (PixelCo (None, 28, 28, 128)       16512     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_15 (PixelCo (None, 28, 28, 128)       16512     \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 28, 28, 1)         129       \n",
      "=================================================================\n",
      "Total params: 532,673\n",
      "Trainable params: 532,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=input_shape)\n",
    "x = PixelConvLayer(\n",
    "    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n",
    ")(inputs)\n",
    "\n",
    "for _ in range(n_residual_blocks):\n",
    "    x = ResidualBlock(filters=128)(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = PixelConvLayer(\n",
    "        mask_type=\"B\",\n",
    "        filters=128,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation=\"relu\",\n",
    "        padding=\"valid\",\n",
    "    )(x)\n",
    "\n",
    "out = Conv2D(\n",
    "    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",
    ")(x)\n",
    "\n",
    "pixel_cnn = keras.Model(inputs, out)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "pixel_cnn.compile(optimizer=adam, loss=\"binary_crossentropy\")\n",
    "\n",
    "pixel_cnn.summary()\n",
    "# pixel_cnn.fit(\n",
    "#     x=data, y=data, batch_size=128, epochs=10, validation_split=0.1, verbose=2\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b46512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer):\n",
    "  for x, y in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      # training=True is only needed if there are layers with different\n",
    "      # behavior during training versus inference (e.g. Dropout).\n",
    "      prediction = model(x, training=True)\n",
    "      loss = loss_fn(prediction, y)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8777948c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b842a630ec31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_pixel_cnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-f2534de57ce9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;31m# training=True is only needed if there are layers with different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m# behavior during training versus inference (e.g. Dropout).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train_pixel_cnn=train(pixel_cnn, data, 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a6e9912",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bdb2a5ddfc77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpixel_cnn_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorFlowV2Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-f2534de57ce9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;31m# training=True is only needed if there are layers with different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m# behavior during training versus inference (e.g. Dropout).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "pixel_cnn_classifier = TensorFlowV2Classifier(model=pixel_cnn, nb_classes=10, train_step=train_pixel_cnn, input_shape=(28,28,1), clip_values=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a04f6c39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The training function `train_step` is required for fitting a model but it has not been defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-992bf56be072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpixel_cnn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_cln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_cln\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/art/estimators/classification/classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/art/estimators/classification/tensorflow.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;34m\"The training function `train_step` is required for fitting a model but it has not been \"\u001b[0m \u001b[0;34m\"defined.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: The training function `train_step` is required for fitting a model but it has not been defined."
     ]
    }
   ],
   "source": [
    "pixel_cnn_classifier.fit(x=x_train_cln, y=y_train_cln, batch_size=64, nb_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5353c811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train_cln))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f0f0b",
   "metadata": {},
   "source": [
    "### **Modification: Disabling eager execution to enable adversarial crafting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87648805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58648ad",
   "metadata": {},
   "source": [
    "### **Load MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa87dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_cln, y_train_cln), (x_test_cln, y_test_cln), min_pixel_value, max_pixel_value = load_mnist()\n",
    "# x_train_cln, y_train_cln = x_train_cln[:1000], y_train_cln[:1000]\n",
    "# x_test_cln, y_test_cln = x_test_cln[:500], y_test_cln[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c4a58",
   "metadata": {},
   "source": [
    "### **Load / Create classifier model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST pre-trained model\n",
    "model = load_model(\"/home/cyber/mnist_trained_model.h5\")\n",
    "\n",
    "#MARVEL pre-trained model\n",
    "# model = load_model(\"/home/cyber/Desktop/Adrian/Xception-10-0.74.hdf5\")\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f6bd9",
   "metadata": {},
   "source": [
    "*Optional step: Train and save a model for future use*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cabb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_cln, y_train_cln, batch_size=64, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ff0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/home/cyber/dataset_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc077ab",
   "metadata": {},
   "source": [
    "## **Section 1 - Attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec9dd4",
   "metadata": {},
   "source": [
    "Step 1: Evaluate the classifier on benign test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cln = classifier.predict(x_test_cln)\n",
    "accuracy = np.sum(np.argmax(predictions_cln, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac38ca",
   "metadata": {},
   "source": [
    "Step 2: Split benign test examples into true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_cln_indexes=[]\n",
    "fp_cln_indexes=[]\n",
    "x_test_cln_tp=[]\n",
    "y_test_cln_tp=[]\n",
    "x_test_cln_fp=[]\n",
    "y_test_cln_fp=[]\n",
    "\n",
    "for k in range(len(predictions_cln)):\n",
    "    if(np.argmax(predictions_cln, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_cln_indexes.append(k)\n",
    "    else:\n",
    "        fp_cln_indexes.append(k)\n",
    "\n",
    "for k in tp_cln_indexes:\n",
    "    x_test_cln_tp.append(x_test_cln[k])\n",
    "    y_test_cln_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_cln_indexes:\n",
    "    x_test_cln_fp.append(x_test_cln[k])\n",
    "    y_test_cln_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_cln_tp = np.array(x_test_cln_tp)\n",
    "x_test_cln_fp = np.array(x_test_cln_fp)\n",
    "\n",
    "print('Benign TP: {:}'.format(len(x_test_cln_tp)))\n",
    "print('Benign FP: {:}'.format(len(x_test_cln_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b91dd",
   "metadata": {},
   "source": [
    "Step 3: Craft adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d730b68",
   "metadata": {},
   "source": [
    "*Basic Iterative Method (BMI)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3987b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adv_crafter = BasicIterativeMethod(classifier, eps=0.3, eps_step=0.1, max_iter=100)\n",
    "x_test_BIM = adv_crafter.generate(x_test_cln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76558c01",
   "metadata": {},
   "source": [
    "*Projected Gradient Descent (PGD)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64259af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_crafter = ProjectedGradientDescent(classifier, eps=0.3, eps_step=0.1, max_iter=100)\n",
    "x_test_PGD = adv_crafter.generate(x_test_cln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2f431",
   "metadata": {},
   "source": [
    "*NewtonFool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_crafter = NewtonFool(classifier, eta=0.01, max_iter=100, verbose=True)\n",
    "x_test_Newton = adv_crafter.generate(x_test_cln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e07528",
   "metadata": {},
   "source": [
    "*Jacobian-based Saliency Map Attack (JSMA)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc57cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_crafter = SaliencyMapMethod(classifier, theta = 0.1, gamma=1, verbose=True)\n",
    "x_test_JSMA = adv_crafter.generate(x_test_cln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f9891",
   "metadata": {},
   "source": [
    "*Adversarial Examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ff9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv = x_test_BIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f4a5f",
   "metadata": {},
   "source": [
    "Step 4: Evaluate the classifier on the adversarial test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee462839",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_adv = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions_adv, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e6a1c",
   "metadata": {},
   "source": [
    "Step 5: Split the adversarial test examples into true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214595e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_adv_indexes=[]\n",
    "fp_adv_indexes=[]\n",
    "x_test_adv_tp=[]\n",
    "y_test_adv_tp=[]\n",
    "x_test_adv_fp=[]\n",
    "y_test_adv_fp=[]\n",
    "\n",
    "for k in range(len(predictions_adv)):\n",
    "    if(np.argmax(predictions_adv, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_adv_indexes.append(k)\n",
    "    else:\n",
    "        fp_adv_indexes.append(k)\n",
    "\n",
    "for k in tp_adv_indexes:\n",
    "    x_test_adv_tp.append(x_test_adv[k])\n",
    "    y_test_adv_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_adv_indexes:\n",
    "    x_test_adv_fp.append(x_test_adv[k])\n",
    "    y_test_adv_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_adv_tp = np.array(x_test_adv_tp)\n",
    "x_test_adv_fp = np.array(x_test_adv_fp)\n",
    "\n",
    "print('Adversarial TP: {:}'.format(len(x_test_adv_tp)))\n",
    "print('Adversarial FP: {:}'.format(len(x_test_adv_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce3b44",
   "metadata": {},
   "source": [
    "Optional step: Plot benign samples and their adversarial counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb593b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(x_test_cln[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(y_test_cln,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(x_test_adv[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(predictions_adv,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a800d61",
   "metadata": {},
   "source": [
    "## **Section 2 - Defence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d97aeb",
   "metadata": {},
   "source": [
    "### **PixelDefend**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f8fb1",
   "metadata": {},
   "source": [
    "Step 1: Transform input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737293cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "defence = PixelDefend(pixel_cnn=pixel_cnn_classifier, clip_values=(min_pixel_value, max_pixel_value), eps=16, verbose=True)\n",
    "\n",
    "x_test_cln_tp_pd = defence(x_test_cln_tp * 255)[0] / 255\n",
    "x_test_cln_fp_pd = defence(x_test_cln_fp * 255)[0] / 255\n",
    "x_test_adv_tp_pd = defence(x_test_adv_tp * 255)[0] / 255\n",
    "x_test_adv_fp_pd = defence(x_test_adv_fp * 255)[0] / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9f6b8",
   "metadata": {},
   "source": [
    "Step 2: Evaluate the classifier on all 4 sets of data after PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ab56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cln_tp_pd = classifier.predict(x_test_cln_tp_pd)\n",
    "accuracy = np.sum(np.argmax(predictions_cln_tp_pd, axis=1) == np.argmax(y_test_cln_tp_pd, axis=1)) / len(y_test_cln_tp_pd)\n",
    "\n",
    "print(\"Accuracy on true positive benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca752f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cln_fp_pd = classifier.predict(x_test_cln_fp_pd)\n",
    "accuracy = np.sum(np.argmax(predictions_cln_fp_pd, axis=1) == np.argmax(y_test_cln_fp_pd, axis=1)) / len(y_test_cln_fp_pd)\n",
    "\n",
    "print(\"Accuracy on false positive benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_adv_tp_pd = classifier.predict(x_test_adv_tp_pd)\n",
    "accuracy = np.sum(np.argmax(predictions_adv_tp_pd, axis=1) == np.argmax(y_test_adv_tp_pd, axis=1)) / len(y_test_adv_tp_pd)\n",
    "\n",
    "print(\"Accuracy on true positive adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c0722",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cln_fp_pd = classifier.predict(x_test_adv_fp_pd)\n",
    "accuracy = np.sum(np.argmax(predictions_adv_fp_pd, axis=1) == np.argmax(y_test_adv_fp_pd, axis=1)) / len(y_test_adv_fp_pd)\n",
    "\n",
    "print(\"Accuracy on false positive benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8236f2",
   "metadata": {},
   "source": [
    "Optional step: Plot all data pre- and post-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot images\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "ax = plt.subplot(4, 1, 1)\n",
    "plt.imshow(x_test_cln_tp[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_cln_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 1, 2)\n",
    "plt.imshow(x_test_cln_tp_pd[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_cln_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 1)\n",
    "plt.imshow(x_test_cln_fp[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_cln_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2)\n",
    "plt.imshow(x_test_cln_fp_pd[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_cln_fp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 3, 1)\n",
    "plt.imshow(x_test_adv_tp[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_adv_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 3, 2)\n",
    "plt.imshow(x_test_adv_tp_pd[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_adv_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 4, 1)\n",
    "plt.imshow(x_test_adv_fp[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_adv_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 4, 2)\n",
    "plt.imshow(x_test_adv_fp_pd[0], cmap='gray')\n",
    "ax.set_title('{:}'.format(np.argmax(y_test_adv_fp_dp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c630",
   "metadata": {},
   "source": [
    "Optional step: Compare the performance of PixelDefend against the adversary over a range of eps values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_range = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "accuracy_original = []\n",
    "accuracy_robust = []\n",
    "\n",
    "adv_crafter = FastGradientMethod(classifier)\n",
    "adv_crafter_robust = FastGradientMethod(robust_classifier)\n",
    "\n",
    "for eps in eps_range:\n",
    "    adv_crafter.set_params(**{'eps': eps})\n",
    "    adv_crafter_robust.set_params(**{'eps': eps})\n",
    "    x_test_adv = adv_crafter.generate(x_test[:100])\n",
    "    x_test_adv_robust = adv_crafter_robust.generate(x_test[:100])\n",
    "    \n",
    "    predictions_original = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    accuracy_original += [np.sum(predictions_original == np.argmax(y_test[:100], axis=1))]\n",
    "    \n",
    "    predictions_robust = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "    accuracy_robust += [np.sum(predictions_robust == np.argmax(y_test[:100], axis=1))]\n",
    "\n",
    "eps_range = eps_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cbbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_range), np.array(accuracy_original), 'b--', label='Original classifier')\n",
    "ax.plot(np.array(eps_range), np.array(accuracy_robust), 'r--', label='Robust classifier')\n",
    "\n",
    "legend = ax.legend(loc='upper right', shadow=True, fontsize='large')\n",
    "#legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8b7ec",
   "metadata": {},
   "source": [
    "### **Load MARVEL dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = [] \n",
    "min_pixel_value = 0\n",
    "max_pixel_value = 1\n",
    "\n",
    "def marvel_class(filename):\n",
    "    switcher={\n",
    "        'HeavyLoadCarrier': 0,\n",
    "        'CombatVessel': 1,\n",
    "        'ContainerShip': 2,\n",
    "        'PassengersShip': 3,\n",
    "        'Ro-roCargo': 4,\n",
    "        'Tanker': 5,\n",
    "        'Tug': 6,\n",
    "        'SupplyVessel': 7,\n",
    "        'Yacht': 8 \n",
    "    }\n",
    "    return switcher.get(filename)\n",
    "\n",
    "def load_training_data(filename):\n",
    "    url = \"/home/cyber/Desktop/Adrian/marvel_data/train_9/\"+filename\n",
    "    for imgname in os.listdir(url):\n",
    "        img = cv2.imread(os.path.join(url,imgname))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (320,240))\n",
    "            x_train.append(img/255)\n",
    "            y_train.append(marvel_class(filename))\n",
    "    return x_train, y_train\n",
    "\n",
    "def load_test_data(filename):\n",
    "    url = \"/home/cyber/Desktop/Adrian/marvel_data/test_9/\"+filename\n",
    "    for imgname in os.listdir(url):\n",
    "        img = cv2.imread(os.path.join(url,imgname))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (320,240))\n",
    "            x_test.append(img/255)\n",
    "            y_test.append(marvel_class(filename))\n",
    "    return x_test, y_test\n",
    "\n",
    "# for filename in os.listdir(\"/home/cyber/Desktop/Adrian/marvel_data/train_9\"):\n",
    "#     load_training_data(filename)\n",
    "#     print(filename)\n",
    "\n",
    "for filename in os.listdir(\"/home/cyber/Desktop/Adrian/marvel_data/test_9\"):\n",
    "    load_test_data(filename)\n",
    "    print(filename)\n",
    "    \n",
    "#load_training_data(\"/home/cyber/Desktop/Adrian/marvel_data/test_9/CombatVessel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6df68",
   "metadata": {},
   "source": [
    "*Modification: Convert MARVEL x_test/x_train from uint8 into float32, to enable classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test, dtype=np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
