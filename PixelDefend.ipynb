{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256084fa",
   "metadata": {},
   "source": [
    "**This notebook focuses on the effectiveness of PixelDefend against adversarial attacks on the MNIST and MARVEL datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbf7b5",
   "metadata": {},
   "source": [
    "**Load prerequisites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d608e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras_radam import RAdam\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from art import config\n",
    "from art.attacks.evasion import FastGradientMethod, DeepFool, ProjectedGradientDescent, SaliencyMapMethod, CarliniL2Method, NewtonFool, BasicIterativeMethod\n",
    "from art.defences.preprocessor import PixelDefend\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.utils import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58648ad",
   "metadata": {},
   "source": [
    "**Load MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa87dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
    "# x_train, y_train = x_train[:10000], y_train[:10000]\n",
    "x_test, y_test = x_test[:500], y_test[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f0f0b",
   "metadata": {},
   "source": [
    "**Modification: Disabling eager execution to enable Section 1, Step 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87648805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc077ab",
   "metadata": {},
   "source": [
    "**Section 1 - Attacks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c4a58",
   "metadata": {},
   "source": [
    "Step 1: Load/Create a classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ddd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/home/cyber/mnist_trained_model.h5\")\n",
    "# model = load_model(\"/home/cyber/marvel_trained_classifier.h5\")\n",
    "\n",
    "classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f6bd9",
   "metadata": {},
   "source": [
    "Optional step: Train and save a model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cabb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "399ff0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/home/cyber/mnist_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec9dd4",
   "metadata": {},
   "source": [
    "Step 2: Evaluate the ART classifier on benign test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1362d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyber/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[128,32,26,26] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node activation_1_1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[activation_5_1/Softmax/_611]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[128,32,26,26] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node activation_1_1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a0b19009707b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Undefended classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on benign test examples: {}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/art/estimators/classification/classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/art/estimators/classification/keras.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, training_mode, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;31m# Apply postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m     return func.predict(\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[1;32m    705\u001b[0m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0;32m--> 706\u001b[0;31m     return predict_loop(\n\u001b[0m\u001b[1;32m    707\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3954\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3956\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   3957\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   3958\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[128,32,26,26] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node activation_1_1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[activation_5_1/Softmax/_611]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[128,32,26,26] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node activation_1_1/Relu}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "\n",
    "print(\"Undefended classifier\")\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b91dd",
   "metadata": {},
   "source": [
    "Step 3: Craft adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96d69560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyber/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# Select crafting algorithm\n",
    "# adv_crafter = SaliencyMapMethod(classifier=classifier, theta = 0.1, gamma=0.3, verbose=True)\n",
    "# adv_crafter = BasicIterativeMethod(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# adv_crafter = ProjectedGradientDescent(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# adv_crafter = NewtonFool(classifier=classifier, eta=0.005, max_iter=25, verbose=True)\n",
    "# adv_crafter = DeepFool(classifier=classifier, epsilon=0.3e-12, max_iter=20)\n",
    "# adv_crafter = CarliniL2Method(classifier=classifier, max_iter=20, verbose=True)\n",
    "adv_crafter = FastGradientMethod(estimator=classifier, eps=0.3)\n",
    "\n",
    "#x_train_adv = adv_crafter.generate(x_train)\n",
    "x_test_adv = adv_crafter.generate(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f4a5f",
   "metadata": {},
   "source": [
    "Step 4: Evaluate the ART classifier on the adversarial test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee462839",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Undefended classifier\")\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce3b44",
   "metadata": {},
   "source": [
    "Optional step: Plot images and their adversarial counterparts for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb593b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10\n",
    "images = x_test[:num]\n",
    "adv_examples = x_test_adv[:num]\n",
    "#labels = y_train[:num]\n",
    "\n",
    "#plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(num):\n",
    "    ax = plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    ax = plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(adv_examples[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    #plt.title('Label: {:}'.format(labels[i]))\n",
    "    #ax.set_title('Label: {}'.format(labels[i]))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6edf76",
   "metadata": {},
   "source": [
    "**Section 2 - Metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8079bc",
   "metadata": {},
   "source": [
    "Metric 1: Empirical Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be695d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = \"fgsm\"\n",
    "score = empirical_robustness(classifier=classifier, x=x_test, attack_name=attack_name)\n",
    "print(\"Empirical robustness of the classifier against {}: {}\".format(attack_name, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8461bb",
   "metadata": {},
   "source": [
    "Metric 2: CLEVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65095118",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clever_u(classifier=classifier, x=x_test[1], nb_batches=10, batch_size=64, radius=25,norm=2)\n",
    "print(\"CLEVER score of the classifier against an untargeted attack: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a800d61",
   "metadata": {},
   "source": [
    "**Section 3 - Defence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce732bc2",
   "metadata": {},
   "source": [
    "Save original adversarial examples for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84509e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_original = x_test_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da4ba2",
   "metadata": {},
   "source": [
    "Creating a seperate 'robust' classifier, to enable side-by-sde analysis of both the original and defended model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/home/cyber/basicmodel.h5\")\n",
    "robust_classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d97aeb",
   "metadata": {},
   "source": [
    "Defence 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b11caa",
   "metadata": {},
   "source": [
    "PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_cnn = load_model(\"/home/cyber/pixelcnn_mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224f0c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 46s 168ms/step - loss: 1026.3543\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 17s 111ms/step - loss: 724.3569\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 17s 111ms/step - loss: 690.8315\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 18s 112ms/step - loss: 672.7293\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 17s 111ms/step - loss: 666.8042\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 18s 111ms/step - loss: 655.8241\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 18s 113ms/step - loss: 651.6655\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 17s 111ms/step - loss: 645.9012\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 639.4327\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 13s 80ms/step - loss: 632.0571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f412c3a8be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a small Pixel CNN++ model to train on MNIST.\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "# from tensorflow_probability.distributions import PixelCNN\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "# tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# (x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
    "x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "x_test, y_test = x_test[:500], y_test[:500]\n",
    "\n",
    "# # Load MNIST from tensorflow_datasets\n",
    "# data = tfds.load('mnist')\n",
    "# train_data, test_data = data['train'], data['test']\n",
    "\n",
    "# def image_preprocess(x):\n",
    "#   x['image'] = tf.cast(x['image'], tf.float32)\n",
    "#   return (x['image'],)  # (input, output) of the model\n",
    "\n",
    "# batch_size = 16\n",
    "# train_it = train_data.map(image_preprocess).batch(batch_size).shuffle(1000)\n",
    "\n",
    "image_shape = (28, 28, 1)\n",
    "# Define a Pixel CNN network\n",
    "dist = tfd.PixelCNN(\n",
    "    image_shape=image_shape,\n",
    "    num_resnet=1,\n",
    "    num_hierarchies=2,\n",
    "    num_filters=32,\n",
    "    num_logistic_mix=5,\n",
    "    dropout_p=.3,\n",
    ")\n",
    "\n",
    "# Define the model input\n",
    "image_input = tfkl.Input(shape=image_shape)\n",
    "\n",
    "# Define the log likelihood for the loss fn\n",
    "log_prob = dist.log_prob(image_input)\n",
    "\n",
    "# Define the model\n",
    "model = tfk.Model(inputs=image_input, outputs=log_prob)\n",
    "model.add_loss(-tf.reduce_mean(log_prob))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(\n",
    "    optimizer=tfk.optimizers.Adam(.001),\n",
    "    metrics=[])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f8fb1",
   "metadata": {},
   "source": [
    "Step 1: Input transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737293cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defence = TotalVarMin(verbose = True)\n",
    "defence = SpatialSmoothing(window_size=5)\n",
    "defence = PixelDefend(clip_values=(min_pixel_value, max_pixel_value), eps=16, pixel_cnn = pixel_cnn, verbose=True)\n",
    "# defence = FeatureSqueezing(clip_values=(min_pixel_value, max_pixel_value), bit_depth=8)\n",
    "\n",
    "x_test_adv = defence(x_test_adv_original * 255)[0] / 255\n",
    "\n",
    "#what does * 255)[0] / 255 do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8236f2",
   "metadata": {},
   "source": [
    "Additional step: Plot images and their adversarial counterparts, pre- and post-transformed, for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10\n",
    "images = x_test[:num]\n",
    "transformed_adv_examples = x_test_adv[:num]\n",
    "pretransformed_adv_examples = x_test_adv_original[:num]\n",
    "#labels = y_train[:num]\n",
    "\n",
    "#plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(num):\n",
    "    ax = plt.subplot(6, 5, i + 1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(6, 5, i + 11)\n",
    "    plt.imshow(pretransformed_adv_examples[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(6, 5, i + 21)\n",
    "    plt.imshow(transformed_adv_examples[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    #plt.title('Label: {:}'.format(labels[i]))\n",
    "    #ax.set_title('Label: {}'.format(labels[i]))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddddb87",
   "metadata": {},
   "source": [
    "Defence 2: Adversarial Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a07c3",
   "metadata": {},
   "source": [
    "Adversarial Training: Method 1 - Data Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa876a9",
   "metadata": {},
   "source": [
    "Step 1: Build a Keras image augmentation object and wrap it in ART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=0.125, height_shift_range=0.125, fill_mode=\"constant\", cval=0.0\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "art_datagen = KerasDataGenerator(\n",
    "    datagen.flow(x=x_train, y=y_train, batch_size=batch_size, shuffle=True),\n",
    "    size=x_train.shape[0],\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc317b32",
   "metadata": {},
   "source": [
    "Step 2: Create adversarial trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv_crafter = BasicIterativeMethod(robust_classifier, eps=0.3, eps_step=0.01, max_iter=40)\n",
    "adv_trainer = AdversarialTrainer(classifier=robust_classifier, attacks=adv_crafter, ratio=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d22da0",
   "metadata": {},
   "source": [
    "Step 3: Perform adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b84fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv_trainer.fit_generator(generator=art_datagen, nb_epochs=5)\n",
    "adv_trainer.fit(x_train, y_train, nb_epochs=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df702a",
   "metadata": {},
   "source": [
    "Optional step: Save the adversarially trained classifier for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.save(\"/home/cyber/pdg_defended_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e0c71",
   "metadata": {},
   "source": [
    "Adversarial Training: Alternative method - Load an existing adversarially trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = get_file('mnist_cnn_robust.h5', extract=False, path=config.ART_DATA_PATH,\n",
    "#                 url='https://www.dropbox.com/s/yutsncaniiy5uy8/mnist_cnn_robust.h5?dl=1')\n",
    "# robust_classifier_model = load_model(path)\n",
    "# robust_classifier = KerasClassifier(clip_values=(min_pixel_value, max_pixel_value), model=robust_classifier_model, use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce2574",
   "metadata": {},
   "source": [
    "Defence: Evaluation of effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14e994",
   "metadata": {},
   "source": [
    "Step 1: Evaluate the defended model on the clean test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e881ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = robust_classifier.predict(x_test)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Defended classifier\")\n",
    "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4f471",
   "metadata": {},
   "source": [
    "Step 2: Evaluate the defended model on the original adversarial test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = robust_classifier.predict(x_test_adv)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Defended classifier\")\n",
    "print(\"Accuracy on original adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c139ca",
   "metadata": {},
   "source": [
    "Step 3: Evaluate the defended model on new adversarial examples produced on the defended model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9332e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adv_crafter = SaliencyMapMethod(classifier=robust_classifier, theta = 1, verbose=True)\n",
    "#adv_crafter = ProjectedGradientDescent(robust_classifier, eps=0.2)\n",
    "adv_crafter = FastGradientMethod(estimator=robust_classifier, eps=0.3)\n",
    "#adv_crafter = DeepFool(classifier=robust_classifier, epsilon=0.2)\n",
    "#adv_crafter = NewtonFool(classifier=robust_classifier, verbose=True)\n",
    "#adv_crafter = CarliniL2Method(classifier=robust_classifier, verbose=True)\n",
    "#adv_crafter = BasicIterativeMethod(robust_classifier, eps=0.3, eps_step=0.01, max_iter=40)\n",
    "\n",
    "x_test_adv_new = adv_crafter.generate(x_test)\n",
    "\n",
    "#The following line is for when a preprocessing defence is used\n",
    "#x_test_adv = defence(x_test_adv * 255)[0] / 255\n",
    "\n",
    "predictions = robust_classifier.predict(x_test_adv_new)\n",
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "print(\"Defended classifier\")\n",
    "print(\"Accuracy on new adversarial test examples: {}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9076b47c",
   "metadata": {},
   "source": [
    "Optional step: Plot images, their original adversarial counterparts, and their new adversarial counterparts for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10\n",
    "images = x_test[:num]\n",
    "adv_examples_new = x_test_adv_new[:num]\n",
    "#labels = y_train[:num]\n",
    "\n",
    "#plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(num):\n",
    "    ax = plt.subplot(6, 5, i + 1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    ax = plt.subplot(6, 5, i + 11)\n",
    "    plt.imshow(adv_examples[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    ax = plt.subplot(6, 5, i + 21)\n",
    "    plt.imshow(adv_examples_new[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    #plt.title('Label: {:}'.format(labels[i]))\n",
    "    #ax.set_title('Label: {}'.format(labels[i]))\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c630",
   "metadata": {},
   "source": [
    "Step 4: Compare the performance of the original and the robust classifier against FGSM over a range of eps values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_range = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "accuracy_original = []\n",
    "accuracy_robust = []\n",
    "\n",
    "adv_crafter = FastGradientMethod(classifier)\n",
    "adv_crafter_robust = FastGradientMethod(robust_classifier)\n",
    "\n",
    "for eps in eps_range:\n",
    "    adv_crafter.set_params(**{'eps': eps})\n",
    "    adv_crafter_robust.set_params(**{'eps': eps})\n",
    "    x_test_adv = adv_crafter.generate(x_test[:100])\n",
    "    x_test_adv_robust = adv_crafter_robust.generate(x_test[:100])\n",
    "    \n",
    "    predictions_original = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "    accuracy_original += [np.sum(predictions_original == np.argmax(y_test[:100], axis=1))]\n",
    "    \n",
    "    predictions_robust = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "    accuracy_robust += [np.sum(predictions_robust == np.argmax(y_test[:100], axis=1))]\n",
    "\n",
    "eps_range = eps_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cbbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_range), np.array(accuracy_original), 'b--', label='Original classifier')\n",
    "ax.plot(np.array(eps_range), np.array(accuracy_robust), 'r--', label='Robust classifier')\n",
    "\n",
    "legend = ax.legend(loc='upper right', shadow=True, fontsize='large')\n",
    "#legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
