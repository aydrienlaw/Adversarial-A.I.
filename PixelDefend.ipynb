{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256084fa",
   "metadata": {},
   "source": [
    "**This notebook focuses on the effectiveness of PixelDefend against adversarial attacks on the MNIST and MARVEL datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929cdf42",
   "metadata": {},
   "source": [
    "## **Section 0 - Setting Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbf7b5",
   "metadata": {},
   "source": [
    "### **Load prerequisites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d608e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, Layer\n",
    "\n",
    "from keras_radam import RAdam\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from art import config\n",
    "from art.attacks.evasion import FastGradientMethod, DeepFool, ProjectedGradientDescent, SaliencyMapMethod, CarliniL2Method, NewtonFool, BasicIterativeMethod\n",
    "from art.defences.preprocessor import PixelDefend\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.estimators.classification import KerasClassifier, TensorFlowV2Classifier, PyTorchClassifier\n",
    "from art.utils import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e0d4",
   "metadata": {},
   "source": [
    "### Load PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dad960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, utils, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8eb4d7",
   "metadata": {},
   "source": [
    "#### Create PixelCNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e99dc5",
   "metadata": {},
   "source": [
    "*Define PixelCNN architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9f3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCNN(nn.Conv2d):\n",
    "\t\"\"\"\n",
    "\tImplementation of Masked CNN Class as explained in A Oord et. al. \n",
    "\tTaken from https://github.com/jzbontar/pixelcnn-pytorch\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, mask_type, *args, **kwargs):\n",
    "\t\tself.mask_type = mask_type\n",
    "\t\tassert mask_type in ['A', 'B'], \"Unknown Mask Type\"\n",
    "\t\tsuper(MaskedCNN, self).__init__(*args, **kwargs)\n",
    "\t\tself.register_buffer('mask', self.weight.data.clone())\n",
    "\n",
    "\t\t_, depth, height, width = self.weight.size()\n",
    "\t\tself.mask.fill_(1)\n",
    "\t\tif mask_type =='A':\n",
    "\t\t\tself.mask[:,:,height//2,width//2:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\t\telse:\n",
    "\t\t\tself.mask[:,:,height//2,width//2+1:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tself.weight.data*=self.mask\n",
    "\t\treturn super(MaskedCNN, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de7eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tNetwork of PixelCNN as described in A Oord et. al. \n",
    "\t\"\"\"\n",
    "\tdef __init__(self, no_layers=8, kernel = 7, channels=64, device=None):\n",
    "\t\tsuper(PixelCNN, self).__init__()\n",
    "\t\tself.no_layers = no_layers\n",
    "\t\tself.kernel = kernel\n",
    "\t\tself.channels = channels\n",
    "\t\tself.layers = {}\n",
    "\t\tself.device = device\n",
    "\n",
    "\t\tself.Conv2d_1 = MaskedCNN('A',1,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_1 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_1= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_2 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_2 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_2= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_3 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_3 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_3= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_4 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_4 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_4= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_5 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_5 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_5= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_6 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_6 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_6= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_7 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_7 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_7= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_8 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_8 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_8= nn.ReLU(True)\n",
    "\n",
    "\t\tself.out = nn.Conv2d(channels, 256, 1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.Conv2d_1(x)\n",
    "\t\tx = self.BatchNorm2d_1(x)\n",
    "\t\tx = self.ReLU_1(x)\n",
    "\n",
    "\t\tx = self.Conv2d_2(x)\n",
    "\t\tx = self.BatchNorm2d_2(x)\n",
    "\t\tx = self.ReLU_2(x)\n",
    "\n",
    "\t\tx = self.Conv2d_3(x)\n",
    "\t\tx = self.BatchNorm2d_3(x)\n",
    "\t\tx = self.ReLU_3(x)\n",
    "\n",
    "\t\tx = self.Conv2d_4(x)\n",
    "\t\tx = self.BatchNorm2d_4(x)\n",
    "\t\tx = self.ReLU_4(x)\n",
    "\n",
    "\t\tx = self.Conv2d_5(x)\n",
    "\t\tx = self.BatchNorm2d_5(x)\n",
    "\t\tx = self.ReLU_5(x)\n",
    "\n",
    "\t\tx = self.Conv2d_6(x)\n",
    "\t\tx = self.BatchNorm2d_6(x)\n",
    "\t\tx = self.ReLU_6(x)\n",
    "\n",
    "\t\tx = self.Conv2d_7(x)\n",
    "\t\tx = self.BatchNorm2d_7(x)\n",
    "\t\tx = self.ReLU_7(x)\n",
    "\n",
    "\t\tx = self.Conv2d_8(x)\n",
    "\t\tx = self.BatchNorm2d_8(x)\n",
    "\t\tx = self.ReLU_8(x)\n",
    "\n",
    "\t\treturn self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4d44d",
   "metadata": {},
   "source": [
    "*Load MNIST pre-trained PixelCNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18302c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "# model.load_state_dict(torch.load('/home/cyber/Desktop/Adrian/PixelCNN_Singh_Hrituraj/model.pt'))\n",
    "# model.load_state_dict(torch.load('/home/cyber/miniconda3/envs/tf-gpu/PixelCNN-Pytorch-master/Models/Model_Checkpoint_Last.pt'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c0940",
   "metadata": {},
   "source": [
    "*Create PixelCNN classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38c3ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PixelCNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "pixelcnn = PyTorchClassifier(\n",
    "    model=model, loss=loss_fn, optimizer=optimizer, input_shape=(28, 28, 1), nb_classes=10, clip_values=(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb00e6",
   "metadata": {},
   "source": [
    "#### Test PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fdfdbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_test_JSMA_MNIST\n",
    "x_test_adv = x_test_JSMA_MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698a128",
   "metadata": {},
   "source": [
    "*Pre-process input for PixelDefend*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df923aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "adv = np.transpose(x_test_adv, (0, -1, 1, 2))\n",
    "print(x_test_adv.shape)\n",
    "print(adv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e51b9",
   "metadata": {},
   "source": [
    "*Transform input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5b89e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defence = PixelDefend(eps=5, pixel_cnn=pixelcnn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47c3d749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ee26445ffe45dcac35dbe660439d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PixelDefend:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x_test_adv = x_test_adv.astype(np.float32)\n",
    "x_test_adv_pd = defence(adv[0:10]*255)[0] / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c9e20",
   "metadata": {},
   "source": [
    "*Post-process output for classification and plotting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97db5d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_pd = np.transpose(x_test_adv_pd, (0, 2, -1, 1))\n",
    "print(x_test_adv_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c16f5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(4,5,i+1)\n",
    "    plt.imshow(x_test_adv_pd[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(4,5,i+11)\n",
    "    plt.imshow(x_test_adv[i], cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f0f0b",
   "metadata": {},
   "source": [
    "### **Modification: Disabling eager execution to enable adversarial crafting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87648805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8b7ec",
   "metadata": {},
   "source": [
    "### **Load MARVEL dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test_cln = []\n",
    "y_test_cln = [] \n",
    "min_pixel_value = 0\n",
    "max_pixel_value = 1\n",
    "\n",
    "def marvel_class(filename):\n",
    "    switcher={\n",
    "        'HeavyLoadCarrier': [1,0,0,0,0,0,0,0,0],\n",
    "        'CombatVessel': [0,1,0,0,0,0,0,0,0],\n",
    "        'ContainerShip': [0,0,1,0,0,0,0,0,0],\n",
    "        'PassengersShip': [0,0,0,1,0,0,0,0,0],\n",
    "        'Ro-roCargo': [0,0,0,0,1,0,0,0,0],\n",
    "        'Tanker': [0,0,0,0,0,1,0,0,0],\n",
    "        'Tug': [0,0,0,0,0,0,1,0,0],\n",
    "        'SupplyVessel': [0,0,0,0,0,0,0,1,0],\n",
    "        'Yacht': [0,0,0,0,0,0,0,0,1]\n",
    "    }\n",
    "    return switcher.get(filename)\n",
    "\n",
    "def load_training_data(filename):\n",
    "    url = \"/home/cyber/Desktop/Adrian/marvel_data/train_9/\"+filename\n",
    "    for imgname in os.listdir(url):\n",
    "        img = cv2.imread(os.path.join(url,imgname))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (320,240))\n",
    "            x_train_cln.append(img/255)\n",
    "            y_train_cln.append(marvel_class(filename))\n",
    "            i = i+1\n",
    "        if i == 100:\n",
    "            break\n",
    "    return x_train_cln, y_train_cln\n",
    "\n",
    "def load_test_data(filename):\n",
    "    url = \"/home/cyber/Desktop/Adrian/marvel_data/test_9/\"+filename\n",
    "    i = 0\n",
    "    for imgname in os.listdir(url):\n",
    "        img = cv2.imread(os.path.join(url,imgname))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (320,240))\n",
    "            x_test_cln.append(img/255)\n",
    "            y_test_cln.append(marvel_class(filename))\n",
    "            i = i + 1\n",
    "        if i == 100:\n",
    "            break\n",
    "    return x_test_cln, y_test_cln\n",
    "\n",
    "# for filename in os.listdir(\"/home/cyber/Desktop/Adrian/marvel_data/train_9\"):\n",
    "#     load_training_data(filename)\n",
    "#     print(filename)\n",
    "\n",
    "for filename in os.listdir(\"/home/cyber/Desktop/Adrian/marvel_data/test_9\"):\n",
    "    load_test_data(filename)\n",
    "    print(filename)\n",
    "    \n",
    "#load_training_data(\"/home/cyber/Desktop/Adrian/marvel_data/test_9/CombatVessel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6df68",
   "metadata": {},
   "source": [
    "*Modification: Convert MARVEL x_test/x_train from uint8 into float32, to enable classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln = np.array(x_test_cln, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58648ad",
   "metadata": {},
   "source": [
    "### **Load MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa87dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_cln, y_train_cln), (x_test_cln, y_test_cln), min_pixel_value, max_pixel_value = load_mnist()\n",
    "# x_test_cln, y_test_cln = x_test_cln[:1000], y_test_cln[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c4a58",
   "metadata": {},
   "source": [
    "### **Load / Create classifier model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c095be",
   "metadata": {},
   "source": [
    "*Load MNIST pre-trained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/home/cyber/mnist_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa596aeb",
   "metadata": {},
   "source": [
    "*Load MARVEL pre-trained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab83ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/cyber/Desktop/Adrian/Xception-10-0.74.hdf5\"\n",
    "model = load_model(model_path, custom_objects={'RAdam': RAdam}, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f6bd9",
   "metadata": {},
   "source": [
    "*Optional step: Train and save a model for future use*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cabb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_cln, y_train_cln, batch_size=64, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ff0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/home/cyber/dataset_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2df92",
   "metadata": {},
   "source": [
    "*Create ART classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d04446",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc077ab",
   "metadata": {},
   "source": [
    "## **Section 1 - Attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec9dd4",
   "metadata": {},
   "source": [
    "Step 1: Evaluate the classifier on the clean test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cln = classifier.predict(x_test_cln)\n",
    "accuracy_cln = np.sum(np.argmax(predictions_cln, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on clean test examples: {}%\".format(accuracy_cln * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac38ca",
   "metadata": {},
   "source": [
    "Step 2: Split the clean test set into its true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909c97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp_cln_indexes=[]\n",
    "fp_cln_indexes=[]\n",
    "x_test_cln_tp=[]\n",
    "y_test_cln_tp=[]\n",
    "x_test_cln_fp=[]\n",
    "y_test_cln_fp=[]\n",
    "\n",
    "for k in range(len(predictions_cln)):\n",
    "    if(np.argmax(predictions_cln, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_cln_indexes.append(k)\n",
    "    else:\n",
    "        fp_cln_indexes.append(k)\n",
    "\n",
    "for k in tp_cln_indexes:\n",
    "    x_test_cln_tp.append(x_test_cln[k])\n",
    "    y_test_cln_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_cln_indexes:\n",
    "    x_test_cln_fp.append(x_test_cln[k])\n",
    "    y_test_cln_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_cln_tp = np.array(x_test_cln_tp)\n",
    "x_test_cln_fp = np.array(x_test_cln_fp)\n",
    "\n",
    "print('Number of clean true positives: {:}'.format(len(x_test_cln_tp)))\n",
    "print('Number of clean false positives: {:}'.format(len(x_test_cln_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b91dd",
   "metadata": {},
   "source": [
    "Step 3: Craft adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e07528",
   "metadata": {},
   "source": [
    "*Jacobian-based Saliency Map Attack (JSMA)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc57cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter = SaliencyMapMethod(classifier=classifier, theta = 0.1, gamma=0.3, verbose=True)\n",
    "# x_test_JSMA_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_JSMA_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d730b68",
   "metadata": {},
   "source": [
    "*Basic Iterative Method (BMI)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3987b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adv_crafter = BasicIterativeMethod(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# x_test_BIM_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_BIM_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76558c01",
   "metadata": {},
   "source": [
    "*Projected Gradient Descent (PGD)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64259af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter = ProjectedGradientDescent(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# x_test_PGD_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_PGD_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2f431",
   "metadata": {},
   "source": [
    "*NewtonFool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter =  NewtonFool(classifier=classifier, eta=0.005, max_iter=25, verbose=True)\n",
    "# x_test_Newton_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_Newton_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5111d",
   "metadata": {},
   "source": [
    "*DeepFool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca35c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter = DeepFool(classifier=classifier, epsilon=1e-06/255, max_iter=50)\n",
    "# x_test_Deep_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_Deep_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f9891",
   "metadata": {},
   "source": [
    "*Load existing Adversarial Examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ff9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_test_JSMA_MNIST\n",
    "x_test_adv = x_test_JSMA_MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f4a5f",
   "metadata": {},
   "source": [
    "Step 4: Evaluate the classifier on the adversarial test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee462839",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_adv = classifier.predict(x_test_adv)\n",
    "accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy_adv * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e6a1c",
   "metadata": {},
   "source": [
    "Step 5: Split the adversarial test set into its true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214595e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_adv_indexes=[]\n",
    "fp_adv_indexes=[]\n",
    "x_test_adv_tp=[]\n",
    "y_test_adv_tp=[]\n",
    "x_test_adv_fp=[]\n",
    "y_test_adv_fp=[]\n",
    "\n",
    "for k in range(len(predictions_adv)):\n",
    "    if(np.argmax(predictions_adv, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_adv_indexes.append(k)\n",
    "    else:\n",
    "        fp_adv_indexes.append(k)\n",
    "\n",
    "for k in tp_adv_indexes:\n",
    "    x_test_adv_tp.append(x_test_adv[k])\n",
    "    y_test_adv_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_adv_indexes:\n",
    "    x_test_adv_fp.append(x_test_adv[k])\n",
    "    y_test_adv_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_adv_tp = np.array(x_test_adv_tp)\n",
    "x_test_adv_fp = np.array(x_test_adv_fp)\n",
    "\n",
    "print('Adversarial TP: {:}'.format(len(x_test_adv_tp)))\n",
    "print('Adversarial FP: {:}'.format(len(x_test_adv_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce3b44",
   "metadata": {},
   "source": [
    "Optional step: Plot clean examples and their adversarial counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb593b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "num = 3\n",
    "\n",
    "for i in range(num):\n",
    "    ax = plt.subplot(4, num, i + 1)\n",
    "    plt.imshow(x_test_cln[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(y_test_cln,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(4, num, i + num + 1)\n",
    "    plt.imshow(x_test_adv[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(predictions_adv,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a800d61",
   "metadata": {},
   "source": [
    "## **Section 2 - Defence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d97aeb",
   "metadata": {},
   "source": [
    "### **PixelDefend**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f8fb1",
   "metadata": {},
   "source": [
    "Step 1: Transform input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147774d2",
   "metadata": {},
   "source": [
    "*Pre-process input for PixelDefend*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f65345",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln_pre = np.transpose(x_test_cln, (0, -1, 1, 2))\n",
    "x_test_cln_tp_pre = np.transpose(x_test_cln_tp, (0, -1, 1, 2))\n",
    "x_test_cln_fp_pre = np.transpose(x_test_cln_fp, (0, -1, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072deb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_pre = np.transpose(x_test_adv, (0, -1, 1, 2))\n",
    "x_test_adv_tp_pre = np.transpose(x_test_adv_tp, (0, -1, 1, 2))\n",
    "x_test_adv_fp_pre = np.transpose(x_test_adv_fp, (0, -1, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6508a6",
   "metadata": {},
   "source": [
    "*Transform input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737293cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defence = PixelDefend(eps=16, pixel_cnn=pixelcnn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln_pre_pd = defence(x_test_cln_pre * 255)[0] / 255\n",
    "x_test_cln_tp_pre_pd = defence(x_test_cln_tp_pre * 255)[0] / 255\n",
    "x_test_cln_fp_pre_pd = defence(x_test_cln_fp_pre * 255)[0] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_pre_pd = defence(x_test_adv_pre * 255)[0] / 255\n",
    "x_test_adv_tp_pre_pd = defence(x_test_adv_tp_pre * 255)[0] / 255\n",
    "x_test_adv_fp_pre_pd = defence(x_test_adv_fp_pre * 255)[0] / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bd636",
   "metadata": {},
   "source": [
    "*Post-processing output for classification and plotting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln_pd = np.transpose(x_test_cln_pre_pd, (0, 2, -1, 1))\n",
    "x_test_cln_tp_pd = np.transpose(x_test_cln_tp_pre_pd, (0, 2, -1, 1))\n",
    "x_test_cln_fp_pd = np.transpose(x_test_cln_fp_pre_pd, (0, 2, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_pd = np.transpose(x_test_adv_pre_pd, (0, 2, -1, 1))\n",
    "x_test_adv_tp_pd = np.transpose(x_test_adv_tp_pre_pd, (0, 2, -1, 1))\n",
    "x_test_adv_fp_pd = np.transpose(x_test_adv_fp_pre_pd, (0, 2, -1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9f6b8",
   "metadata": {},
   "source": [
    "Step 2: Evaluate the classifier on all 4 sets of data after PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ab56c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions_cln_pd = classifier.predict(x_test_cln_pd)\n",
    "accuracy_cln_pd = np.sum(np.argmax(predictions_cln_pd, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Effect of PixelDefend on entire clean test set: {:.2f}%\".format((accuracy_cln_pd - accuracy_cln) * 100))\n",
    " \n",
    "predictions_cln_tp_pd = classifier.predict(x_test_cln_tp_pd)\n",
    "accuracy_cln_tp_pd = np.sum(np.argmax(predictions_cln_tp_pd, axis=1) == np.argmax(y_test_cln_tp, axis=1)) / len(y_test_cln_tp)\n",
    "\n",
    "# print(\"\\nAccuracy on true positive clean test examples after PixelDefend: {:.2f}%\".format(accuracy_cln_tp_pd * 100))\n",
    "print(\"\\nAccuracy drop on true positive clean test examples after PixelDefend: {:.2f}%\".format((1 - accuracy_cln_tp_pd) * 100))\n",
    "\n",
    "predictions_cln_fp_pd = classifier.predict(x_test_cln_fp_pd)\n",
    "accuracy_cln_fp_pd = np.sum(np.argmax(predictions_cln_fp_pd, axis=1) == np.argmax(y_test_cln_fp, axis=1)) / len(y_test_cln_fp)\n",
    "\n",
    "print(\"\\nAccuracy increase on false positive clean test examples after PixelDefend: {:.2f}%\".format(accuracy_cln_fp_pd * 100))\n",
    "\n",
    "predictions_adv_pd = classifier.predict(x_test_adv_pd)\n",
    "accuracy_adv_pd = np.sum(np.argmax(predictions_adv_pd, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"\\nEffect of PixelDefend on entire adversarial test set: {:.2f}%\".format((accuracy_adv_pd-accuracy_adv) * 100))\n",
    "\n",
    "predictions_adv_tp_pd = classifier.predict(x_test_adv_tp_pd)\n",
    "accuracy_adv_tp_pd = np.sum(np.argmax(predictions_adv_tp_pd, axis=1) == np.argmax(y_test_adv_tp, axis=1)) / len(y_test_adv_tp)\n",
    "\n",
    "# print(\"\\nAccuracy on true positive adversarial test examples after PixelDefend: {:.2f}%\".format(accuracy_adv_tp_pd * 100))\n",
    "print(\"\\nAccuracy drop on true positive adversarial test examples after PixelDefend: {:.2f}%\".format((1 - accuracy_adv_tp_pd) * 100))\n",
    "\n",
    "predictions_adv_fp_pd = classifier.predict(x_test_adv_fp_pd)\n",
    "accuracy_adv_fp_pd = np.sum(np.argmax(predictions_adv_fp_pd, axis=1) == np.argmax(y_test_adv_fp, axis=1)) / len(y_test_adv_fp)\n",
    "\n",
    "print(\"\\nAccuracy increase on false positive adversarial test examples after PixelDefend: {:.2f}%\".format(accuracy_adv_fp_pd * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8236f2",
   "metadata": {},
   "source": [
    "Step 3: Plot all data pre- and post-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee10bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "predictions_cln_tp = classifier.predict(x_test_cln_tp)\n",
    "predictions_cln_fp = classifier.predict(x_test_cln_fp)\n",
    "predictions_adv_tp = classifier.predict(x_test_adv_tp)\n",
    "predictions_adv_fp = classifier.predict(x_test_adv_fp)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "#Plot clean true positives\n",
    "ax = plt.subplot(4, 2, 2*0+1)\n",
    "plt.imshow(x_test_cln_tp[0], cmap='gray')\n",
    "ax.set_title('Clean TP: {:}'.format(np.argmax(predictions_cln_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*0+2)\n",
    "plt.imshow(x_test_cln_tp_pd[0], cmap='gray')\n",
    "ax.set_title('Clean TP after PixelDefend: {:}'.format(np.argmax(predictions_cln_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot clean false positives\n",
    "ax = plt.subplot(4, 2, 2*1+1)\n",
    "plt.imshow(x_test_cln_fp[0], cmap='gray')\n",
    "ax.set_title('Clean FP: {:}\\nTrue class: {:}'.format(np.argmax(predictions_cln_fp,axis=1)[0], np.argmax(y_test_cln_fp,axis=1)[0]), fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*1+2)\n",
    "plt.imshow(x_test_cln_fp_pd[0], cmap='gray')\n",
    "ax.set_title('Clean FP after PixelDefend: {:}\\nTrue class: {:}'.format(np.argmax(predictions_cln_fp_pd,axis=1)[0], np.argmax(y_test_cln_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot adversarial true positives\n",
    "ax = plt.subplot(4, 2, 2*2+1)\n",
    "plt.imshow(x_test_adv_tp[0], cmap='gray')\n",
    "ax.set_title('Adversarial TP: {:}'.format(np.argmax(predictions_adv_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*2+2)\n",
    "plt.imshow(x_test_adv_tp_pd[0], cmap='gray')\n",
    "ax.set_title('Adversarial TP after PixelDefend: {:}'.format(np.argmax(predictions_adv_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot adversarial false positivies\n",
    "ax = plt.subplot(4, 2, 2*3+1)\n",
    "plt.imshow(x_test_adv_fp[0], cmap='gray')\n",
    "ax.set_title('Adversarial FP: {:}\\nTrue class: {:}'.format(np.argmax(predictions_adv_fp,axis=1)[0], np.argmax(y_test_adv_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*3+2)\n",
    "plt.imshow(x_test_adv_fp_pd[0], cmap='gray')\n",
    "ax.set_title('Adversarial FP after PixelDefend: {:}\\nTrue class: {:}'.format(np.argmax(predictions_adv_fp_pd,axis=1)[0], np.argmax(y_test_adv_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21800af9",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c630",
   "metadata": {},
   "source": [
    "Optional step: Compare the performance of TotalVarMin against the adversary over a range of eps values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_range = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# accuracy_original = []\n",
    "# accuracy_robust = []\n",
    "\n",
    "# adv_crafter = FastGradientMethod(classifier)\n",
    "# adv_crafter_robust = FastGradientMethod(robust_classifier)\n",
    "\n",
    "# for eps in eps_range:\n",
    "#     adv_crafter.set_params(**{'eps': eps})\n",
    "#     adv_crafter_robust.set_params(**{'eps': eps})\n",
    "#     x_test_adv = adv_crafter.generate(x_test[:100])\n",
    "#     x_test_adv_robust = adv_crafter_robust.generate(x_test[:100])\n",
    "    \n",
    "#     predictions_original = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "#     accuracy_original += [np.sum(predictions_original == np.argmax(y_test[:100], axis=1))]\n",
    "    \n",
    "#     predictions_robust = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "#     accuracy_robust += [np.sum(predictions_robust == np.argmax(y_test[:100], axis=1))]\n",
    "\n",
    "# eps_range = eps_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cbbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(np.array(eps_range), np.array(accuracy_original), 'b--', label='Original classifier')\n",
    "# ax.plot(np.array(eps_range), np.array(accuracy_robust), 'r--', label='Robust classifier')\n",
    "\n",
    "# legend = ax.legend(loc='upper right', shadow=True, fontsize='large')\n",
    "# #legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "# plt.xlabel('Attack strength (eps)')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09a11c",
   "metadata": {},
   "source": [
    "## PixelCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3078815",
   "metadata": {},
   "source": [
    "### Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, utils, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def causal_mask(width, height, starting_point):\n",
    "    row_grid, col_grid = np.meshgrid(np.arange(width), np.arange(height), indexing='ij')\n",
    "    mask = np.logical_or(\n",
    "        row_grid < starting_point[0],\n",
    "        np.logical_and(row_grid == starting_point[0], col_grid <= starting_point[1]))\n",
    "    return mask\n",
    "\n",
    "def conv_mask(width, height, include_center=False):\n",
    "    return 1.0 * causal_mask(width, height, starting_point=(width//2, height//2 + include_center - 1))\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        _, n_channels, width, height = self.weight.size()\n",
    "\n",
    "        mask = conv_mask(width, height, include_center=mask_type=='B')\n",
    "        self.register_buffer('mask', torch.from_numpy(mask).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bee7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    n_channels = 4\n",
    "    kernel_size = 7\n",
    "    padding = 3\n",
    "    n_pixels_out = 2 # binary 0/1 pixels\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            MaskedConv2d('A', in_channels=1, out_channels=self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=self.n_channels, out_channels=self.n_pixels_out, kernel_size=1)\n",
    "        )\n",
    "        self.fc = nn.Linear(28*28, 28*28*64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        logit_output = self.fc(x)\n",
    "        logit_output = logit_output.view(-1, 64, 1, 28, 28)\n",
    "\n",
    "        return logit_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25319c6a",
   "metadata": {},
   "source": [
    "### Attempt 2: PixelCNN by Jzbontar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b17c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('torch.cuda.is_available():', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ee6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from torch import nn, optim, cuda, backends\n",
    "from torch.utils import data\n",
    "backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        assert mask_type in {'A', 'B'}\n",
    "        self.register_buffer('mask', self.weight.data.clone())\n",
    "        _, _, kH, kW = self.weight.size()\n",
    "        self.mask.fill_(1)\n",
    "        self.mask[:, :, kH // 2, kW // 2 + (mask_type == 'B'):] = 0\n",
    "        self.mask[:, :, kH // 2 + 1:] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)\n",
    "\n",
    "fm = 64\n",
    "model = nn.Sequential(\n",
    "    MaskedConv2d('A', 1,  fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    nn.Conv2d(fm, 256, 1))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "tr = data.DataLoader(datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "                     batch_size=128, shuffle=True, num_workers=1, pin_memory=True)\n",
    "te = data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor()),\n",
    "                     batch_size=128, shuffle=False, num_workers=1, pin_memory=True)\n",
    "sample = torch.Tensor(144, 1, 28, 28).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# for epoch in range(5):\n",
    "#     # train\n",
    "#     err_tr = []\n",
    "#     cuda.synchronize()\n",
    "#     time_tr = time.time()\n",
    "#     model.train(True)\n",
    "#     for input, _ in tr:\n",
    "#         input = Variable(input.cuda(non_blocking=True))\n",
    "#         target = Variable((input.data[:,0] * 255).long())\n",
    "#         loss = F.cross_entropy(model(input), target)\n",
    "#         err_tr.append(loss.data.item())\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     cuda.synchronize()\n",
    "#     time_tr = time.time() - time_tr\n",
    "\n",
    "#     # compute error on test set\n",
    "#     err_te = []\n",
    "#     cuda.synchronize()\n",
    "#     time_te = time.time()\n",
    "#     model.train(False)\n",
    "#     for input, _ in te:\n",
    "#         input = Variable(input.cuda(non_blocking=True), volatile=True)\n",
    "#         target = Variable((input.data[:,0] * 255).long())\n",
    "#         loss = F.cross_entropy(model(input), target)\n",
    "#         err_te.append(loss.data.item())\n",
    "#     cuda.synchronize()\n",
    "#     time_te = time.time() - time_te\n",
    "\n",
    "#     # sample\n",
    "#     sample.fill_(0)\n",
    "#     model.train(False)\n",
    "#     for i in range(28):\n",
    "#         for j in range(28):\n",
    "#             out = model(Variable(sample, volatile=True))\n",
    "#             probs = F.softmax(out[:, :, i, j]).data\n",
    "#             sample[:, :, i, j] = torch.multinomial(probs, 1).float() / 255.\n",
    "#     utils.save_image(sample, 'sample_{:02d}.png'.format(epoch), nrow=12, padding=0)\n",
    "\n",
    "#     print('epoch={}; nll_tr={:.7f}; nll_te={:.7f}; time_tr={:.1f}s; time_te={:.1f}s'.format(\n",
    "#         epoch, np.mean(err_tr), np.mean(err_te), time_tr, time_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64925eb5",
   "metadata": {},
   "source": [
    "### Attempt 3: PixelCNN by Kamenbliznashki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4dd390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PixelCNN implementation\n",
    "References:\n",
    "    1. van den Oord, Pixel Recurrent Neural Networks 2016a\n",
    "    2. van den Oord, Conditional Image Generation with PixelCNN Decoders, 2016c\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "image_dims=(1,28,28), n_bits=4, n_channels=128, n_out_conv_channels=1024, kernel_size=5, n_res_layers=12, n_cond_classes=10\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Model components\n",
    "# --------------------\n",
    "\n",
    "def pixelcnn_gate(x):\n",
    "    a, b = x.chunk(2,1)\n",
    "    return torch.tanh(a) * torch.sigmoid(b)\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, *args, mask_type=None, mask_n_channels=None, gated=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "#         nn.init.constant_(bias, 0.)\n",
    "\n",
    "        # set up mask -- cf PixelRNN paper Figure 2 Right: masks A and B\n",
    "        mask_type = mask_type\n",
    "        mask_n_channels = mask_n_channels\n",
    "        center_row = kernel_size[0] // 2\n",
    "        center_col = kernel_size[1] // 2\n",
    "\n",
    "        mask = torch.ones_like(weight)         # shape (out_channels, in_channels, kernel_height, kernel_width)\n",
    "\n",
    "        # mask out 1/ rows below the middle and 2/ center row pixels right of middle\n",
    "        if center_row == 0:                         # case when kernel_size = (1,k) in horizontal stack\n",
    "            mask[:, :, :, center_col+1:] = 0\n",
    "        elif center_col == 0:                       # case when kernel_size = (k,1)\n",
    "            mask[:, :, center_row+1:, :] = 0\n",
    "        else:                                       # case when kernel_size = (k,k)\n",
    "            mask[:, :, center_row+1:, :] = 0\n",
    "            mask[:, :, center_row, center_col+1:] = 0\n",
    "\n",
    "        # mask out center pixel in future channels -- mask A current channel is 0; mask B current channel is 1\n",
    "        for i in range(mask_n_channels):\n",
    "            for j in range(mask_n_channels):\n",
    "                if (mask_type=='a' and i >= j) or (mask_type=='b' and i > j):\n",
    "                    mask[j::mask_n_channels, i::mask_n_channels, center_row, center_col] = 0\n",
    "\n",
    "        # mask out center row (vertical stack in a Gated Residual Layer); cf Conditional image generation with PixelCNN Decoders\n",
    "        if mask_type == 'vstack':\n",
    "            mask[:, :, center_row, :] = 0\n",
    "\n",
    "        if gated:\n",
    "            # pixelcnn gate splits the input in two along the channel dim;\n",
    "            # ensure that both chunks receive the same mask by replicating the first half of the mask over the second\n",
    "            mask = mask.chunk(2,0)[0].repeat(2,1,1,1)\n",
    "\n",
    "        # final mask\n",
    "        register_buffer('mask', mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight.data *= mask\n",
    "        return super().forward(x)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = super().__repr__()\n",
    "        return s[:-1] + ', mask_type={}, mask_n_channels={}'.format(mask_type, mask_n_channels) + s[-1]\n",
    "\n",
    "\n",
    "class GatedResidualLayer(nn.Module):\n",
    "    \"\"\" Figure 2 in Conditional image generation with PixelCNN Decoders \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, mask_type, mask_n_channels, n_cond_classes, norm_layer):\n",
    "        super().__init__()\n",
    "        residual = (in_channels==out_channels)\n",
    "        norm_layer = norm_layer\n",
    "\n",
    "        v   = MaskedConv2d(in_channels, 2*out_channels, kernel_size, padding=kernel_size//2,\n",
    "                                mask_type='vstack', mask_n_channels=mask_n_channels, gated=True)\n",
    "        h   = MaskedConv2d(in_channels, 2*out_channels, (1, kernel_size), padding=(0, kernel_size//2),\n",
    "                                mask_type=mask_type, mask_n_channels=mask_n_channels, gated=True)\n",
    "        v2h = MaskedConv2d(2*out_channels, 2*out_channels, kernel_size=1,\n",
    "                                mask_type=mask_type, mask_n_channels=mask_n_channels, gated=True)\n",
    "        h2h = MaskedConv2d(out_channels, out_channels, kernel_size=1,\n",
    "                                mask_type=mask_type, mask_n_channels=mask_n_channels, gated=False)\n",
    "\n",
    "        if n_cond_classes:\n",
    "            proj_h = nn.Linear(n_cond_classes, 2*out_channels)\n",
    "\n",
    "        if norm_layer:\n",
    "            norm_layer_v = nn.BatchNorm2d(out_channels)\n",
    "            norm_layer_h = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x_v, x_h, h=None):\n",
    "        # projection of h if included for conditional generation (cf paper section 2.3 -- added before the pixelcnn_gate)\n",
    "        proj_y = proj_h(h)[:,:,None,None] if h is not None else 0\n",
    "\n",
    "        # vertical stack\n",
    "        x_v_out = v(x_v)\n",
    "        x_v2h = v2h(x_v_out) + proj_y\n",
    "        x_v_out = pixelcnn_gate(x_v_out)\n",
    "\n",
    "        # horizontal stack\n",
    "        x_h_out = h(x_h) + x_v2h + proj_y\n",
    "        x_h_out = pixelcnn_gate(x_h_out)\n",
    "        x_h_out = h2h(x_h_out)\n",
    "\n",
    "        # residual connection\n",
    "        if residual:\n",
    "            x_h_out = x_h_out + x_h\n",
    "\n",
    "        # normalization\n",
    "        if norm_layer:\n",
    "            x_v_out = norm_layer_v(x_v_out)\n",
    "            x_h_out = norm_layer_h(x_h_out)\n",
    "\n",
    "        return x_v_out, x_h_out\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'residual={}, norm_layer={}'.format(residual, norm_layer)\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# PixelCNN\n",
    "# --------------------\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, image_dims, n_bits, n_channels, n_out_conv_channels, kernel_size, n_res_layers, n_cond_classes, norm_layer=True):\n",
    "        super().__init__()\n",
    "        C, H, W = image_dims\n",
    "\n",
    "        input_conv = MaskedConv2d(C, 2*n_channels, kernel_size=7, padding=3, mask_type='a', mask_n_channels=C, gated=True)\n",
    "        res_layers = nn.ModuleList([\n",
    "            GatedResidualLayer(n_channels, n_channels, kernel_size, 'b', C, n_cond_classes, norm_layer)\n",
    "            for _ in range(n_res_layers)])\n",
    "        conv_out1 = MaskedConv2d(n_channels, 2*n_out_conv_channels, kernel_size=1, mask_type='b', mask_n_channels=C, gated=True)\n",
    "        conv_out2 = MaskedConv2d(n_out_conv_channels, 2*n_out_conv_channels, kernel_size=1, mask_type='b', mask_n_channels=C, gated=True)\n",
    "        output = MaskedConv2d(n_out_conv_channels, C * 2**n_bits, kernel_size=1, mask_type='b', mask_n_channels=C)\n",
    "\n",
    "        if n_cond_classes:\n",
    "            proj_h = nn.Linear(n_cond_classes, 2*n_channels)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = pixelcnn_gate(input_conv(x) + (proj_h(h)[:,:,None,None] if h is not None else 0.))\n",
    "        x_v, x_h = x, x\n",
    "\n",
    "        for l in res_layers:\n",
    "            x_v, x_h = l(x_v, x_h)\n",
    "\n",
    "        out = pixelcnn_gate(conv_out1(x_h))\n",
    "        out = pixelcnn_gate(conv_out2(out))\n",
    "        out = output(out)\n",
    "\n",
    "        return out.reshape(B, -1, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ddf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN(image_dims=(1,28,28), n_bits=4, n_channels=128, n_out_conv_channels=1024, kernel_size=5, n_res_layers=12, n_cond_classes=10)\n",
    "model.load_state_dict(torch.load('/home/cyber/miniconda3/envs/tf-gpu/pixel_models-master/results/pixelcnn/2021-05-04_08-44-00/checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0814a27",
   "metadata": {},
   "source": [
    "### Attempt 4: PixelCNN by Singh-Hrituraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCNN(nn.Conv2d):\n",
    "\t\"\"\"\n",
    "\tImplementation of Masked CNN Class as explained in A Oord et. al. \n",
    "\tTaken from https://github.com/jzbontar/pixelcnn-pytorch\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, mask_type, *args, **kwargs):\n",
    "\t\tself.mask_type = mask_type\n",
    "\t\tassert mask_type in ['A', 'B'], \"Unknown Mask Type\"\n",
    "\t\tsuper(MaskedCNN, self).__init__(*args, **kwargs)\n",
    "\t\tself.register_buffer('mask', self.weight.data.clone())\n",
    "\n",
    "\t\t_, depth, height, width = self.weight.size()\n",
    "\t\tself.mask.fill_(1)\n",
    "\t\tif mask_type =='A':\n",
    "\t\t\tself.mask[:,:,height//2,width//2:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\t\telse:\n",
    "\t\t\tself.mask[:,:,height//2,width//2+1:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tself.weight.data*=self.mask\n",
    "\t\treturn super(MaskedCNN, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tNetwork of PixelCNN as described in A Oord et. al. \n",
    "\t\"\"\"\n",
    "\tdef __init__(self, no_layers=8, kernel = 7, channels=64, device=None):\n",
    "\t\tsuper(PixelCNN, self).__init__()\n",
    "\t\tself.no_layers = no_layers\n",
    "\t\tself.kernel = kernel\n",
    "\t\tself.channels = channels\n",
    "\t\tself.layers = {}\n",
    "\t\tself.device = device\n",
    "\n",
    "\t\tself.Conv2d_1 = MaskedCNN('A',1,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_1 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_1= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_2 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_2 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_2= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_3 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_3 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_3= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_4 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_4 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_4= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_5 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_5 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_5= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_6 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_6 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_6= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_7 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_7 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_7= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_8 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_8 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_8= nn.ReLU(True)\n",
    "\n",
    "\t\tself.out = nn.Conv2d(channels, 256, 1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.Conv2d_1(x)\n",
    "\t\tx = self.BatchNorm2d_1(x)\n",
    "\t\tx = self.ReLU_1(x)\n",
    "\n",
    "\t\tx = self.Conv2d_2(x)\n",
    "\t\tx = self.BatchNorm2d_2(x)\n",
    "\t\tx = self.ReLU_2(x)\n",
    "\n",
    "\t\tx = self.Conv2d_3(x)\n",
    "\t\tx = self.BatchNorm2d_3(x)\n",
    "\t\tx = self.ReLU_3(x)\n",
    "\n",
    "\t\tx = self.Conv2d_4(x)\n",
    "\t\tx = self.BatchNorm2d_4(x)\n",
    "\t\tx = self.ReLU_4(x)\n",
    "\n",
    "\t\tx = self.Conv2d_5(x)\n",
    "\t\tx = self.BatchNorm2d_5(x)\n",
    "\t\tx = self.ReLU_5(x)\n",
    "\n",
    "\t\tx = self.Conv2d_6(x)\n",
    "\t\tx = self.BatchNorm2d_6(x)\n",
    "\t\tx = self.ReLU_6(x)\n",
    "\n",
    "\t\tx = self.Conv2d_7(x)\n",
    "\t\tx = self.BatchNorm2d_7(x)\n",
    "\t\tx = self.ReLU_7(x)\n",
    "\n",
    "\t\tx = self.Conv2d_8(x)\n",
    "\t\tx = self.BatchNorm2d_8(x)\n",
    "\t\tx = self.ReLU_8(x)\n",
    "\n",
    "\t\treturn self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13854fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "# model.load_state_dict(torch.load('/home/cyber/Desktop/Adrian/PixelCNN_Singh_Hrituraj/model.pt'))\n",
    "# model.load_state_dict(torch.load('/home/cyber/miniconda3/envs/tf-gpu/PixelCNN-Pytorch-master/Models/Model_Checkpoint_Last.pt'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer.load_state_dict(torch.load('/home/cyber/Desktop/Adrian/PixelCNN_Singh_Hrituraj/optimizer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ec8c9",
   "metadata": {},
   "source": [
    "### Attempt 5: PixelCNN by pclucas14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537d2ee",
   "metadata": {},
   "source": [
    "### Train PixelCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a4f7f",
   "metadata": {},
   "source": [
    "*Train PixelCNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "lr = 0.002\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root=r'/home/cyber/Desktop/Adrian', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95024cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(input=model(data), target=torch.squeeze(data).long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(model.state_dict(), '/home/cyber/Desktop/Adrian/PixelCNN_Singh_Hrituraj/model.pt')\n",
    "      torch.save(optimizer.state_dict(), '/home/cyber/Desktop/Adrian/PixelCNN_Singh_Hrituraj/optimizer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d051781",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d114b",
   "metadata": {},
   "source": [
    "### Pre-process input for PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc25943",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = torch.from_numpy(x_test_adv)\n",
    "adv = adv.transpose(1,-1)\n",
    "adv = adv.numpy()\n",
    "# adv = adv.to('cuda')\n",
    "print(x_test_adv.shape)\n",
    "print(adv.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
