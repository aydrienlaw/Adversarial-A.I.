{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256084fa",
   "metadata": {},
   "source": [
    "**This notebook focuses on the effectiveness of PixelDefend against adversarial attacks on the MNIST and MARVEL datasets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929cdf42",
   "metadata": {},
   "source": [
    "## **Section 0 - Setting Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbf7b5",
   "metadata": {},
   "source": [
    "### **Load prerequisites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d608e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, Layer\n",
    "\n",
    "from keras_radam import RAdam\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from art import config\n",
    "from art.attacks.evasion import FastGradientMethod, DeepFool, ProjectedGradientDescent, SaliencyMapMethod, CarliniL2Method, NewtonFool, BasicIterativeMethod\n",
    "from art.defences.preprocessor import PixelDefend\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.estimators.classification import KerasClassifier, TensorFlowV2Classifier, PyTorchClassifier\n",
    "from art.utils import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2e0d4",
   "metadata": {},
   "source": [
    "### Load PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dad960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, utils, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c880d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e2f82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): False\n"
     ]
    }
   ],
   "source": [
    "print('torch.cuda.is_available():', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b47079dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d1f31efeaa53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m te = data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor()),\n\u001b[0;32m     41\u001b[0m                      batch_size=128, shuffle=False, num_workers=1, pin_memory=True)\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m144\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\adrian\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from torch import nn, optim, cuda, backends\n",
    "from torch.utils import data\n",
    "backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        assert mask_type in {'A', 'B'}\n",
    "        self.register_buffer('mask', self.weight.data.clone())\n",
    "        _, _, kH, kW = self.weight.size()\n",
    "        self.mask.fill_(1)\n",
    "        self.mask[:, :, kH // 2, kW // 2 + (mask_type == 'B'):] = 0\n",
    "        self.mask[:, :, kH // 2 + 1:] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)\n",
    "\n",
    "fm = 64\n",
    "net = nn.Sequential(\n",
    "    MaskedConv2d('A', 1,  fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    nn.Conv2d(fm, 256, 1))\n",
    "net.eval()\n",
    "net = net.to(device)\n",
    "\n",
    "tr = data.DataLoader(datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "                     batch_size=128, shuffle=True, num_workers=1, pin_memory=True)\n",
    "te = data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor()),\n",
    "                     batch_size=128, shuffle=False, num_workers=1, pin_memory=True)\n",
    "sample = torch.Tensor(144, 1, 28, 28).cuda()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "for epoch in range(25):\n",
    "    # train\n",
    "    err_tr = []\n",
    "    cuda.synchronize()\n",
    "    time_tr = time.time()\n",
    "    net.train(True)\n",
    "    for input, _ in tr:\n",
    "        input = Variable(input.cuda(non_blocking=True))\n",
    "        target = Variable((input.data[:,0] * 255).long())\n",
    "        loss = F.cross_entropy(net(input), target)\n",
    "        err_tr.append(loss.data[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    cuda.synchronize()\n",
    "    time_tr = time.time() - time_tr\n",
    "\n",
    "    # compute error on test set\n",
    "    err_te = []\n",
    "    cuda.synchronize()\n",
    "    time_te = time.time()\n",
    "    net.train(False)\n",
    "    for input, _ in te:\n",
    "        input = Variable(input.cuda(non_blocking=True), volatile=True)\n",
    "        target = Variable((input.data[:,0] * 255).long())\n",
    "        loss = F.cross_entropy(net(input), target)\n",
    "        err_te.append(loss.data[0])\n",
    "    cuda.synchronize()\n",
    "    time_te = time.time() - time_te\n",
    "\n",
    "    # sample\n",
    "    sample.fill_(0)\n",
    "    net.train(False)\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            out = net(Variable(sample, volatile=True))\n",
    "            probs = F.softmax(out[:, :, i, j]).data\n",
    "            sample[:, :, i, j] = torch.multinomial(probs, 1).float() / 255.\n",
    "    utils.save_image(sample, 'sample_{:02d}.png'.format(epoch), nrow=12, padding=0)\n",
    "\n",
    "    print('epoch={}; nll_tr={:.7f}; nll_te={:.7f}; time_tr={:.1f}s; time_te={:.1f}s'.format(\n",
    "        epoch, np.mean(err_tr), np.mean(err_te), time_tr, time_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8eb4d7",
   "metadata": {},
   "source": [
    "#### Create PixelCNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4d44d",
   "metadata": {},
   "source": [
    "*MNIST pre-trained PixelCNN*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c0940",
   "metadata": {},
   "source": [
    "*Create PixelCNN classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c3ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "pixelcnn = PyTorchClassifier(\n",
    "    model=model, loss=loss_fn, optimizer=optimizer, input_shape=(28, 28, 1), nb_classes=10, clip_values=(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb00e6",
   "metadata": {},
   "source": [
    "#### Test PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfdbee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_test_JSMA_MNIST\n",
    "x_test_adv = x_test_JSMA_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b89e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defence = PixelDefend(eps=5, pixel_cnn=pixelcnn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3d749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_adv = x_test_adv.astype(np.float32)\n",
    "x_test_adv_pd = defence(x_test_adv*255)[0] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c16f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_test_adv_pd[i], cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f0f0b",
   "metadata": {},
   "source": [
    "### **Modification: Disabling eager execution to enable adversarial crafting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87648805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8b7ec",
   "metadata": {},
   "source": [
    "### **Load MARVEL dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test_cln = []\n",
    "y_test_cln = [] \n",
    "min_pixel_value = 0\n",
    "max_pixel_value = 1\n",
    "\n",
    "def marvel_class(filename):\n",
    "    switcher={\n",
    "        'HeavyLoadCarrier': [1,0,0,0,0,0,0,0,0],\n",
    "        'CombatVessel': [0,1,0,0,0,0,0,0,0],\n",
    "        'ContainerShip': [0,0,1,0,0,0,0,0,0],\n",
    "        'PassengersShip': [0,0,0,1,0,0,0,0,0],\n",
    "        'Ro-roCargo': [0,0,0,0,1,0,0,0,0],\n",
    "        'Tanker': [0,0,0,0,0,1,0,0,0],\n",
    "        'Tug': [0,0,0,0,0,0,1,0,0],\n",
    "        'SupplyVessel': [0,0,0,0,0,0,0,1,0],\n",
    "        'Yacht': [0,0,0,0,0,0,0,0,1]\n",
    "    }\n",
    "    return switcher.get(filename)\n",
    "\n",
    "def load_training_data(filename):\n",
    "    url = \"/home/cyber/Desktop/Adrian/marvel_data/train_9/\"+filename\n",
    "    for imgname in os.listdir(url):\n",
    "        img = cv2.imread(os.path.join(url,imgname))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (320,240))\n",
    "            x_train_cln.append(img/255)\n",
    "            y_train_cln.append(marvel_class(filename))\n",
    "            i = i+1\n",
    "        if i == 100:\n",
    "            break\n",
    "    return x_train_cln, y_train_cln\n",
    "\n",
    "def load_test_data(filename):\n",
    "    url = \"/home/cyber/Desktop/Adrian/marvel_data/test_9/\"+filename\n",
    "    i = 0\n",
    "    for imgname in os.listdir(url):\n",
    "        img = cv2.imread(os.path.join(url,imgname))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (320,240))\n",
    "            x_test_cln.append(img/255)\n",
    "            y_test_cln.append(marvel_class(filename))\n",
    "            i = i + 1\n",
    "        if i == 100:\n",
    "            break\n",
    "    return x_test_cln, y_test_cln\n",
    "\n",
    "# for filename in os.listdir(\"/home/cyber/Desktop/Adrian/marvel_data/train_9\"):\n",
    "#     load_training_data(filename)\n",
    "#     print(filename)\n",
    "\n",
    "for filename in os.listdir(\"/home/cyber/Desktop/Adrian/marvel_data/test_9\"):\n",
    "    load_test_data(filename)\n",
    "    print(filename)\n",
    "    \n",
    "#load_training_data(\"/home/cyber/Desktop/Adrian/marvel_data/test_9/CombatVessel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6df68",
   "metadata": {},
   "source": [
    "*Modification: Convert MARVEL x_test/x_train from uint8 into float32, to enable classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln = np.array(x_test_cln, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58648ad",
   "metadata": {},
   "source": [
    "### **Load MNIST dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa87dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_cln, y_train_cln), (x_test_cln, y_test_cln), min_pixel_value, max_pixel_value = load_mnist()\n",
    "# x_test_cln, y_test_cln = x_test_cln[:1000], y_test_cln[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c4a58",
   "metadata": {},
   "source": [
    "### **Load / Create classifier model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c095be",
   "metadata": {},
   "source": [
    "*MNIST pre-trained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ddd668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/home/cyber/mnist_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa596aeb",
   "metadata": {},
   "source": [
    "*MARVEL pre-trained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab83ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/cyber/Desktop/Adrian/Xception-10-0.74.hdf5\"\n",
    "model = load_model(model_path, custom_objects={'RAdam': RAdam}, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f6bd9",
   "metadata": {},
   "source": [
    "*Optional step: Train and save a model for future use*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cabb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_cln, y_train_cln, batch_size=64, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ff0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/home/cyber/dataset_trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2df92",
   "metadata": {},
   "source": [
    "*Create ART classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d04446",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc077ab",
   "metadata": {},
   "source": [
    "## **Section 1 - Attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec9dd4",
   "metadata": {},
   "source": [
    "Step 1: Evaluate the classifier on the clean test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362d452",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cln = classifier.predict(x_test_cln)\n",
    "accuracy_cln = np.sum(np.argmax(predictions_cln, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on clean test examples: {}%\".format(accuracy_cln * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac38ca",
   "metadata": {},
   "source": [
    "Step 2: Split clean test examples into true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7909c97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tp_cln_indexes=[]\n",
    "fp_cln_indexes=[]\n",
    "x_test_cln_tp=[]\n",
    "y_test_cln_tp=[]\n",
    "x_test_cln_fp=[]\n",
    "y_test_cln_fp=[]\n",
    "\n",
    "for k in range(len(predictions_cln)):\n",
    "    if(np.argmax(predictions_cln, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_cln_indexes.append(k)\n",
    "    else:\n",
    "        fp_cln_indexes.append(k)\n",
    "\n",
    "for k in tp_cln_indexes:\n",
    "    x_test_cln_tp.append(x_test_cln[k])\n",
    "    y_test_cln_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_cln_indexes:\n",
    "    x_test_cln_fp.append(x_test_cln[k])\n",
    "    y_test_cln_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_cln_tp = np.array(x_test_cln_tp)\n",
    "x_test_cln_fp = np.array(x_test_cln_fp)\n",
    "\n",
    "print('Number of clean true positives: {:}'.format(len(x_test_cln_tp)))\n",
    "print('Number of clean false positives: {:}'.format(len(x_test_cln_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b91dd",
   "metadata": {},
   "source": [
    "Step 3: Craft adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e07528",
   "metadata": {},
   "source": [
    "*Jacobian-based Saliency Map Attack (JSMA)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc57cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter = SaliencyMapMethod(classifier=classifier, theta = 0.1, gamma=0.3, verbose=True)\n",
    "# x_test_JSMA_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_JSMA_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d730b68",
   "metadata": {},
   "source": [
    "*Basic Iterative Method (BMI)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3987b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adv_crafter = BasicIterativeMethod(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# x_test_BIM_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_BIM_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76558c01",
   "metadata": {},
   "source": [
    "*Projected Gradient Descent (PGD)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64259af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter = ProjectedGradientDescent(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# x_test_PGD_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_PGD_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2f431",
   "metadata": {},
   "source": [
    "*NewtonFool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab72fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter =  NewtonFool(classifier=classifier, eta=0.005, max_iter=25, verbose=True)\n",
    "# x_test_Newton_MNIST = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_Newton_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter =  NewtonFool(classifier=classifier, eta=0.005, max_iter=25, verbose=True)\n",
    "# x_test_Newton_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_Newton_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5111d",
   "metadata": {},
   "source": [
    "*DeepFool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca35c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_crafter = DeepFool(classifier=classifier, epsilon=1e-06/255, max_iter=50)\n",
    "# x_test_Deep_MARVEL = adv_crafter.generate(x_test_cln)\n",
    "# %store x_test_Deep_MARVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f9891",
   "metadata": {},
   "source": [
    "*Adversarial Examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ff9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_test_JSMA_MNIST\n",
    "x_test_adv = x_test_JSMA_MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f4a5f",
   "metadata": {},
   "source": [
    "Step 4: Evaluate the classifier on the adversarial test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee462839",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_adv = classifier.predict(x_test_adv)\n",
    "accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy_adv * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e6a1c",
   "metadata": {},
   "source": [
    "Step 5: Split the adversarial test examples into true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214595e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_adv_indexes=[]\n",
    "fp_adv_indexes=[]\n",
    "x_test_adv_tp=[]\n",
    "y_test_adv_tp=[]\n",
    "x_test_adv_fp=[]\n",
    "y_test_adv_fp=[]\n",
    "\n",
    "for k in range(len(predictions_adv)):\n",
    "    if(np.argmax(predictions_adv, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_adv_indexes.append(k)\n",
    "    else:\n",
    "        fp_adv_indexes.append(k)\n",
    "\n",
    "for k in tp_adv_indexes:\n",
    "    x_test_adv_tp.append(x_test_adv[k])\n",
    "    y_test_adv_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_adv_indexes:\n",
    "    x_test_adv_fp.append(x_test_adv[k])\n",
    "    y_test_adv_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_adv_tp = np.array(x_test_adv_tp)\n",
    "x_test_adv_fp = np.array(x_test_adv_fp)\n",
    "\n",
    "print('Adversarial TP: {:}'.format(len(x_test_adv_tp)))\n",
    "print('Adversarial FP: {:}'.format(len(x_test_adv_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce3b44",
   "metadata": {},
   "source": [
    "Optional step: Plot clean examples and their adversarial counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb593b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "num = 3\n",
    "\n",
    "for i in range(num):\n",
    "    ax = plt.subplot(4, num, i + 1)\n",
    "    plt.imshow(x_test_cln[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(y_test_cln,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(4, num, i + num + 1)\n",
    "    plt.imshow(x_test_adv[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(predictions_adv,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a800d61",
   "metadata": {},
   "source": [
    "## **Section 2 - Defence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d97aeb",
   "metadata": {},
   "source": [
    "### **PixelDefend**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f8fb1",
   "metadata": {},
   "source": [
    "Step 1: Transform input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737293cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defence = PixelDefend(eps=16, pixel_cnn=pixelcnn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448e021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_adv = x_test_adv.astype(np.float32)\n",
    "x_test_adv_pd = defence(x_test_adv*255)[0] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a341d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(1,1,1)\n",
    "plt.imshow(x_test_adv_pd[4], cmap='gray')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec3ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln_pd = defence(x_test_cln*255)[0] / 255\n",
    "x_test_cln_tp_pd = defence(x_test_cln_tp * 255)[0] / 255\n",
    "x_test_cln_fp_pd = defence(x_test_cln_fp * 255)[0] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_pd = defence(x_test_adv*255)[0] / 255\n",
    "x_test_adv_tp_pd = defence(x_test_adv_tp * 255)[0] / 255\n",
    "x_test_adv_fp_pd = defence(x_test_adv_fp * 255)[0] / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9f6b8",
   "metadata": {},
   "source": [
    "Step 2: Evaluate the classifier on all 4 sets of data after PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ab56c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions_cln_pd = classifier.predict(x_test_cln_pd)\n",
    "accuracy_cln_pd = np.sum(np.argmax(predictions_cln_pd, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Effect of PixelDefend on entire clean test set: {:.2f}%\".format((accuracy_cln_pd - accuracy_cln) * 100))\n",
    " \n",
    "predictions_cln_tp_pd = classifier.predict(x_test_cln_tp_pd)\n",
    "accuracy_cln_tp_pd = np.sum(np.argmax(predictions_cln_tp_pd, axis=1) == np.argmax(y_test_cln_tp, axis=1)) / len(y_test_cln_tp)\n",
    "\n",
    "# print(\"\\nAccuracy on true positive clean test examples after PixelDefend: {:.2f}%\".format(accuracy_cln_tp_pd * 100))\n",
    "print(\"\\nAccuracy drop on true positive clean test examples after PixelDefend: {:.2f}%\".format((1 - accuracy_cln_tp_pd) * 100))\n",
    "\n",
    "predictions_cln_fp_pd = classifier.predict(x_test_cln_fp_pd)\n",
    "accuracy_cln_fp_pd = np.sum(np.argmax(predictions_cln_fp_pd, axis=1) == np.argmax(y_test_cln_fp, axis=1)) / len(y_test_cln_fp)\n",
    "\n",
    "print(\"\\nAccuracy increase on false positive clean test examples after PixelDefend: {:.2f}%\".format(accuracy_cln_fp_pd * 100))\n",
    "\n",
    "predictions_adv_pd = classifier.predict(x_test_adv_pd)\n",
    "accuracy_adv_pd = np.sum(np.argmax(predictions_adv_pd, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"\\nEffect of PixelDefend on entire adversarial test set: {:.2f}%\".format((accuracy_adv_pd-accuracy_adv) * 100))\n",
    "\n",
    "predictions_adv_tp_pd = classifier.predict(x_test_adv_tp_pd)\n",
    "accuracy_adv_tp_pd = np.sum(np.argmax(predictions_adv_tp_pd, axis=1) == np.argmax(y_test_adv_tp, axis=1)) / len(y_test_adv_tp)\n",
    "\n",
    "# print(\"\\nAccuracy on true positive adversarial test examples after PixelDefend: {:.2f}%\".format(accuracy_adv_tp_pd * 100))\n",
    "print(\"\\nAccuracy drop on true positive adversarial test examples after PixelDefend: {:.2f}%\".format((1 - accuracy_adv_tp_pd) * 100))\n",
    "\n",
    "predictions_adv_fp_pd = classifier.predict(x_test_adv_fp_pd)\n",
    "accuracy_adv_fp_pd = np.sum(np.argmax(predictions_adv_fp_pd, axis=1) == np.argmax(y_test_adv_fp, axis=1)) / len(y_test_adv_fp)\n",
    "\n",
    "print(\"\\nAccuracy increase on false positive adversarial test examples after PixelDefend: {:.2f}%\".format(accuracy_adv_fp_pd * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8236f2",
   "metadata": {},
   "source": [
    "Optional step: Plot all data pre- and post-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee10bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "predictions_cln_tp = classifier.predict(x_test_cln_tp)\n",
    "predictions_cln_fp = classifier.predict(x_test_cln_fp)\n",
    "predictions_adv_tp = classifier.predict(x_test_adv_tp)\n",
    "predictions_adv_fp = classifier.predict(x_test_adv_fp)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "#Plot clean true positives\n",
    "ax = plt.subplot(4, 2, 2*0+1)\n",
    "plt.imshow(x_test_cln_tp[0], cmap='gray')\n",
    "ax.set_title('Clean TP: {:}'.format(np.argmax(predictions_cln_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*0+2)\n",
    "plt.imshow(x_test_cln_tp_pd[0], cmap='gray')\n",
    "ax.set_title('Clean TP after PixelDefend: {:}'.format(np.argmax(predictions_cln_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot clean false positives\n",
    "ax = plt.subplot(4, 2, 2*1+1)\n",
    "plt.imshow(x_test_cln_fp[0], cmap='gray')\n",
    "ax.set_title('Clean FP: {:}\\nTrue class: {:}'.format(np.argmax(predictions_cln_fp,axis=1)[0], np.argmax(y_test_cln_fp,axis=1)[0]), fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*1+2)\n",
    "plt.imshow(x_test_cln_fp_pd[0], cmap='gray')\n",
    "ax.set_title('Clean FP after PixelDefend: {:}\\nTrue class: {:}'.format(np.argmax(predictions_cln_fp_pd,axis=1)[0], np.argmax(y_test_cln_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot adversarial true positives\n",
    "ax = plt.subplot(4, 2, 2*2+1)\n",
    "plt.imshow(x_test_adv_tp[0], cmap='gray')\n",
    "ax.set_title('Adversarial TP: {:}'.format(np.argmax(predictions_adv_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*2+2)\n",
    "plt.imshow(x_test_adv_tp_pd[0], cmap='gray')\n",
    "ax.set_title('Adversarial TP after PixelDefend: {:}'.format(np.argmax(predictions_adv_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot adversarial false positivies\n",
    "ax = plt.subplot(4, 2, 2*3+1)\n",
    "plt.imshow(x_test_adv_fp[0], cmap='gray')\n",
    "ax.set_title('Adversarial FP: {:}\\nTrue class: {:}'.format(np.argmax(predictions_adv_fp,axis=1)[0], np.argmax(y_test_adv_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*3+2)\n",
    "plt.imshow(x_test_adv_fp_pd[0], cmap='gray')\n",
    "ax.set_title('Adversarial FP after PixelDefend: {:}\\nTrue class: {:}'.format(np.argmax(predictions_adv_fp_pd,axis=1)[0], np.argmax(y_test_adv_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21800af9",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c630",
   "metadata": {},
   "source": [
    "Optional step: Compare the performance of TotalVarMin against the adversary over a range of eps values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_range = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# accuracy_original = []\n",
    "# accuracy_robust = []\n",
    "\n",
    "# adv_crafter = FastGradientMethod(classifier)\n",
    "# adv_crafter_robust = FastGradientMethod(robust_classifier)\n",
    "\n",
    "# for eps in eps_range:\n",
    "#     adv_crafter.set_params(**{'eps': eps})\n",
    "#     adv_crafter_robust.set_params(**{'eps': eps})\n",
    "#     x_test_adv = adv_crafter.generate(x_test[:100])\n",
    "#     x_test_adv_robust = adv_crafter_robust.generate(x_test[:100])\n",
    "    \n",
    "#     predictions_original = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "#     accuracy_original += [np.sum(predictions_original == np.argmax(y_test[:100], axis=1))]\n",
    "    \n",
    "#     predictions_robust = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "#     accuracy_robust += [np.sum(predictions_robust == np.argmax(y_test[:100], axis=1))]\n",
    "\n",
    "# eps_range = eps_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cbbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(np.array(eps_range), np.array(accuracy_original), 'b--', label='Original classifier')\n",
    "# ax.plot(np.array(eps_range), np.array(accuracy_robust), 'r--', label='Robust classifier')\n",
    "\n",
    "# legend = ax.legend(loc='upper right', shadow=True, fontsize='large')\n",
    "# #legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "# plt.xlabel('Attack strength (eps)')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3078815",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, utils, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def causal_mask(width, height, starting_point):\n",
    "    row_grid, col_grid = np.meshgrid(np.arange(width), np.arange(height), indexing='ij')\n",
    "    mask = np.logical_or(\n",
    "        row_grid < starting_point[0],\n",
    "        np.logical_and(row_grid == starting_point[0], col_grid <= starting_point[1]))\n",
    "    return mask\n",
    "\n",
    "def conv_mask(width, height, include_center=False):\n",
    "    return 1.0 * causal_mask(width, height, starting_point=(width//2, height//2 + include_center - 1))\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        _, n_channels, width, height = self.weight.size()\n",
    "\n",
    "        mask = conv_mask(width, height, include_center=mask_type=='B')\n",
    "        self.register_buffer('mask', torch.from_numpy(mask).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bee7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    n_channels = 4\n",
    "    kernel_size = 7\n",
    "    padding = 3\n",
    "    n_pixels_out = 2 # binary 0/1 pixels\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            MaskedConv2d('A', in_channels=1, out_channels=self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=self.n_channels, out_channels=self.n_pixels_out, kernel_size=1)\n",
    "        )\n",
    "        self.fc = nn.Linear(28*28, 28*28*64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        logit_output = self.fc(x)\n",
    "        logit_output = logit_output.view(-1, 64, 1, 28, 28)\n",
    "\n",
    "        return logit_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0814a27",
   "metadata": {},
   "source": [
    "## Attempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a4af2",
   "metadata": {},
   "source": [
    "*Create PixelCNN architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2647c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedCNN(nn.Conv2d):\n",
    "\t\"\"\"\n",
    "\tImplementation of Masked CNN Class as explained in A Oord et. al. \n",
    "\tTaken from https://github.com/jzbontar/pixelcnn-pytorch\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, mask_type, *args, **kwargs):\n",
    "\t\tself.mask_type = mask_type\n",
    "\t\tassert mask_type in ['A', 'B'], \"Unknown Mask Type\"\n",
    "\t\tsuper(MaskedCNN, self).__init__(*args, **kwargs)\n",
    "\t\tself.register_buffer('mask', self.weight.data.clone())\n",
    "\n",
    "\t\t_, depth, height, width = self.weight.size()\n",
    "\t\tself.mask.fill_(1)\n",
    "\t\tif mask_type =='A':\n",
    "\t\t\tself.mask[:,:,height//2,width//2:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\t\telse:\n",
    "\t\t\tself.mask[:,:,height//2,width//2+1:] = 0\n",
    "\t\t\tself.mask[:,:,height//2+1:,:] = 0\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tself.weight.data*=self.mask\n",
    "\t\treturn super(MaskedCNN, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tNetwork of PixelCNN as described in A Oord et. al. \n",
    "\t\"\"\"\n",
    "\tdef __init__(self, no_layers=8, kernel = 7, channels=64, device=None):\n",
    "\t\tsuper(PixelCNN, self).__init__()\n",
    "\t\tself.no_layers = no_layers\n",
    "\t\tself.kernel = kernel\n",
    "\t\tself.channels = channels\n",
    "\t\tself.layers = {}\n",
    "\t\tself.device = device\n",
    "\n",
    "\t\tself.Conv2d_1 = MaskedCNN('A',1,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_1 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_1= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_2 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_2 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_2= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_3 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_3 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_3= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_4 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_4 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_4= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_5 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_5 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_5= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_6 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_6 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_6= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_7 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_7 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_7= nn.ReLU(True)\n",
    "\n",
    "\t\tself.Conv2d_8 = MaskedCNN('B',channels,channels, kernel, 1, kernel//2, bias=False)\n",
    "\t\tself.BatchNorm2d_8 = nn.BatchNorm2d(channels)\n",
    "\t\tself.ReLU_8= nn.ReLU(True)\n",
    "\n",
    "\t\tself.out = nn.Conv2d(channels, 256, 1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.Conv2d_1(x)\n",
    "\t\tx = self.BatchNorm2d_1(x)\n",
    "\t\tx = self.ReLU_1(x)\n",
    "\n",
    "\t\tx = self.Conv2d_2(x)\n",
    "\t\tx = self.BatchNorm2d_2(x)\n",
    "\t\tx = self.ReLU_2(x)\n",
    "\n",
    "\t\tx = self.Conv2d_3(x)\n",
    "\t\tx = self.BatchNorm2d_3(x)\n",
    "\t\tx = self.ReLU_3(x)\n",
    "\n",
    "\t\tx = self.Conv2d_4(x)\n",
    "\t\tx = self.BatchNorm2d_4(x)\n",
    "\t\tx = self.ReLU_4(x)\n",
    "\n",
    "\t\tx = self.Conv2d_5(x)\n",
    "\t\tx = self.BatchNorm2d_5(x)\n",
    "\t\tx = self.ReLU_5(x)\n",
    "\n",
    "\t\tx = self.Conv2d_6(x)\n",
    "\t\tx = self.BatchNorm2d_6(x)\n",
    "\t\tx = self.ReLU_6(x)\n",
    "\n",
    "\t\tx = self.Conv2d_7(x)\n",
    "\t\tx = self.BatchNorm2d_7(x)\n",
    "\t\tx = self.ReLU_7(x)\n",
    "\n",
    "\t\tx = self.Conv2d_8(x)\n",
    "\t\tx = self.BatchNorm2d_8(x)\n",
    "\t\tx = self.ReLU_8(x)\n",
    "\n",
    "\t\treturn self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13854fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "# model.load_state_dict(torch.load('/home/cyber/miniconda3/envs/tf-gpu/PixelCNN-Pytorch-master/Models/Model_Checkpoint_Last.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537d2ee",
   "metadata": {},
   "source": [
    "## PixelCNN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a4f7f",
   "metadata": {},
   "source": [
    "*Train PixelCNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "lr = 0.002\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root=r'/home/cyber/Desktop/Adrian', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root=r'/home/cyber/Desktop/Adrian', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95024cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(input=model(data), target=torch.squeeze(data).long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(model.state_dict(), '/home/cyber/Desktop/Adrian/results/model.pt')\n",
    "      torch.save(optimizer.state_dict(), '/home/cyber/Desktop/Adrian/results/optimizer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d051781",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
