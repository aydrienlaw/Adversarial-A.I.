{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256084fa",
   "metadata": {},
   "source": [
    "**This notebook evalutes the effectiveness of PixelDefend against adversarial attacks on the CIFAR-10 dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929cdf42",
   "metadata": {},
   "source": [
    "## **Section 0 - Setting Up**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dbf7b5",
   "metadata": {},
   "source": [
    "### **Load prerequisites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d608e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, Layer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from art import config\n",
    "from art.attacks.evasion import FastGradientMethod, DeepFool, ProjectedGradientDescent, SaliencyMapMethod, CarliniL2Method, NewtonFool, BasicIterativeMethod\n",
    "from art.defences.preprocessor import PixelDefend\n",
    "# from art.defences.trainer import AdversarialTrainer\n",
    "from art.estimators.classification import KerasClassifier, PyTorchClassifier\n",
    "from art.utils import load_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bf8e9",
   "metadata": {},
   "source": [
    "### Create PixelCNN for PixelDefend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e86647",
   "metadata": {},
   "source": [
    "*Note: Load PyTorch before disabling eager execution to optimize CUDA memory*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693efaf7",
   "metadata": {},
   "source": [
    "#### Load PyTorch prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2225b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# import torchvision\n",
    "# from torchvision import datasets, utils, transforms\n",
    "# from torch.autograd import Variable\n",
    "# from torch.nn.utils import weight_norm as wn\n",
    "# from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79652df9",
   "metadata": {},
   "source": [
    "#### Create PixelCNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e8523f",
   "metadata": {},
   "source": [
    "*Define PixelCNN architecture*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02873649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, c_in, c_out, k_size, stride, pad):\n",
    "        \"\"\"2D Convolution with masked weight for Autoregressive connection\"\"\"\n",
    "        super(MaskedConv2d, self).__init__(\n",
    "            c_in, c_out, k_size, stride, pad, bias=False)\n",
    "        assert mask_type in ['A', 'B']\n",
    "        self.mask_type = mask_type\n",
    "        ch_out, ch_in, height, width = self.weight.size()\n",
    "\n",
    "        # Mask\n",
    "        #         -------------------------------------\n",
    "        #        |  1       1       1       1       1 |\n",
    "        #        |  1       1       1       1       1 |\n",
    "        #        |  1       1    1 if B     0       0 |   H // 2\n",
    "        #        |  0       0       0       0       0 |   H // 2 + 1\n",
    "        #        |  0       0       0       0       0 |\n",
    "        #         -------------------------------------\n",
    "        #  index    0       1     W//2    W//2+1\n",
    "\n",
    "        mask = torch.ones(ch_out, ch_in, height, width)\n",
    "        if mask_type == 'A':\n",
    "            # First Convolution Only\n",
    "            # => Restricting connections to\n",
    "            #    already predicted neighborhing channels in current pixel\n",
    "            mask[:, :, height // 2, width // 2:] = 0\n",
    "            mask[:, :, height // 2 + 1:] = 0\n",
    "        else:\n",
    "            mask[:, :, height // 2, width // 2 + 1:] = 0\n",
    "            mask[:, :, height // 2] = 0\n",
    "        self.register_buffer('mask', mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)\n",
    "\n",
    "\n",
    "def maskAConv(c_in=3, c_out=256, k_size=7, stride=1, pad=3):\n",
    "    \"\"\"2D Masked Convolution (type A)\"\"\"\n",
    "    return nn.Sequential(\n",
    "        MaskedConv2d('A', c_in, c_out, k_size, stride, pad),\n",
    "        nn.BatchNorm2d(c_out))\n",
    "\n",
    "\n",
    "class MaskBConvBlock(nn.Module):\n",
    "    def __init__(self, h=128, k_size=3, stride=1, pad=1):\n",
    "        \"\"\"1x1 Conv + 2D Masked Convolution (type B) + 1x1 Conv\"\"\"\n",
    "        super(MaskBConvBlock, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2 * h, h, 1),  # 1x1\n",
    "            nn.BatchNorm2d(h),\n",
    "            nn.ReLU(),\n",
    "            MaskedConv2d('B', h, h, k_size, stride, pad),\n",
    "            nn.BatchNorm2d(h),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(h, 2 * h, 1),  # 1x1\n",
    "            nn.BatchNorm2d(2 * h)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Residual connection\"\"\"\n",
    "        return self.net(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef37d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, n_channel=3, h=128, discrete_channel=256):\n",
    "        \"\"\"PixelCNN Model\"\"\"\n",
    "        super(PixelCNN, self).__init__()\n",
    "\n",
    "        self.discrete_channel = discrete_channel\n",
    "\n",
    "        self.MaskAConv = maskAConv(n_channel, 2 * h, k_size=7, stride=1, pad=3)\n",
    "        MaskBConv = []\n",
    "        for i in range(15):\n",
    "            MaskBConv.append(MaskBConvBlock(h, k_size=3, stride=1, pad=1))\n",
    "        self.MaskBConv = nn.Sequential(*MaskBConv)\n",
    "\n",
    "        # 1x1 conv to 3x256 channels\n",
    "        self.out = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2 * h, 1024, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1024, n_channel * discrete_channel, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, channel, height, width]\n",
    "        Return:\n",
    "            out [batch_size, channel, height, width, 256]\n",
    "        \"\"\"\n",
    "        batch_size, c_in, height, width = x.size()\n",
    "\n",
    "        # [batch_size, 2h, 32, 32]\n",
    "        x = self.MaskAConv(x)\n",
    "\n",
    "        # [batch_size, 2h, 32, 32]\n",
    "        x = self.MaskBConv(x)\n",
    "\n",
    "        # [batch_size, 3x256, 32, 32]\n",
    "        x = self.out(x)\n",
    "\n",
    "        # [batch_size, 3, 256, 32, 32]\n",
    "        x = x.view(batch_size, c_in, self.discrete_channel, height, width)\n",
    "\n",
    "        # [batch_size, 3, 32, 32, 256]\n",
    "        x = x.permute(0, 1, 3, 4, 2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb906d2",
   "metadata": {},
   "source": [
    "*Load the weights of a CIFAR-10 pre-trained PixelCNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9fb6819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "# model.load_state_dict(torch.load('/home/cyber/Desktop/Adrian/PixelCNN_pclucas14/pcnn_lr.0.00040_nr-resnet5_nr-filters160_889.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a427c",
   "metadata": {},
   "source": [
    "*Create PixelCNN classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6291801d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "pixelcnn = PyTorchClassifier(\n",
    "    model=model, loss=loss_fn, optimizer=optimizer, input_shape=(3, 32, 32), nb_classes=10,clip_values=(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb76e79",
   "metadata": {},
   "source": [
    "#### Test PixelDefend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb3e24",
   "metadata": {},
   "source": [
    "*Get adversarial examples*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c2ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r x_test_JSMA_cifar10\n",
    "x_test_adv = x_test_JSMA_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e374c",
   "metadata": {},
   "source": [
    "*Pre-process input for PixelDefend*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cf55f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "adv = np.transpose(x_test_adv, (0, -1, 1, 2))\n",
    "print(x_test_adv.shape)\n",
    "print(adv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c008688",
   "metadata": {},
   "source": [
    "*Transform input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acf3fab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defence = PixelDefend(eps=5, pixel_cnn=pixelcnn, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39f6c904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aa66b031304716a0a7dda6308f7ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PixelDefend:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 100\n",
    "x_test_adv_pd = defence(adv[0:num])[0] \n",
    "# x_test_adv_pd = defence(adv[0:num]*255)[0] / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a671c",
   "metadata": {},
   "source": [
    "*Post-process output for classification and plotting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69babf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_pd = np.transpose(x_test_adv_pd, (0, 2, -1, 1))\n",
    "print(x_test_adv_pd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aadeb8",
   "metadata": {},
   "source": [
    "*Classification*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56e3e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adrian\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "Accuracy on adversarial test examples before PixelDefend: 0.0%, and after PixelDefend: 55.00000000000001%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adrian\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predictions_adv = classifier.predict(x_test_adv)\n",
    "accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == np.argmax(y_test_cln[:num], axis=1)) / num\n",
    "\n",
    "predictions_adv_pd = classifier.predict(x_test_adv_pd)\n",
    "accuracy_adv_pd = np.sum(np.argmax(predictions_adv_pd, axis=1) == np.argmax(y_test_cln[:num], axis=1)) / num\n",
    "\n",
    "print(\"Accuracy on adversarial test examples before PixelDefend: {}%, and after PixelDefend: {}%\".format(accuracy_adv*100, accuracy_adv_pd * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94099724",
   "metadata": {},
   "source": [
    "*Plot images pre- and post-transformation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "plt.figure(figsize=(100, 100))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(4,5,i+1)\n",
    "    plt.imshow(x_test_adv_pd[i], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(4,5,i+11)\n",
    "    plt.imshow(x_test_adv[i], cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f0f0b",
   "metadata": {},
   "source": [
    "### **Disable eager execution to enable adversarial crafting and ART classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87648805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58648ad",
   "metadata": {},
   "source": [
    "### **Load CIFAR-10 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b29e1450",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_cln, y_train_cln), (x_test_cln, y_test_cln), min_pixel_value, max_pixel_value = load_cifar10()\n",
    "# x_test_cln, y_test_cln = x_test_cln[:1000], y_test_cln[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c4a58",
   "metadata": {},
   "source": [
    "### **Create CIFAR-10 classifier model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7941dfa3",
   "metadata": {},
   "source": [
    "*Load CIFAR-10 pre-trained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2237a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/home/cyber/Desktop/Adrian/cifar10_trained_model.h5\"\n",
    "model_path = \"/Users/Adrian/Downloads/Sem 3.2/Models & Checkpoints/cifar10_trained_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e2df92",
   "metadata": {},
   "source": [
    "*Create ART classifier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4d04446",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc077ab",
   "metadata": {},
   "source": [
    "## **Section 1 - Attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec9dd4",
   "metadata": {},
   "source": [
    "Step 1: Evaluate the classifier on the clean test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1362d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on clean test examples: 88.87%\n"
     ]
    }
   ],
   "source": [
    "predictions_cln = classifier.predict(x_test_cln)\n",
    "accuracy_cln = np.sum(np.argmax(predictions_cln, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on clean test examples: {}%\".format(accuracy_cln * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac38ca",
   "metadata": {},
   "source": [
    "Step 2: Split the clean test set into its true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7909c97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clean true positives: 8887\n",
      "Number of clean false positives: 1113\n"
     ]
    }
   ],
   "source": [
    "tp_cln_indexes=[]\n",
    "fp_cln_indexes=[]\n",
    "x_test_cln_tp=[]\n",
    "y_test_cln_tp=[]\n",
    "x_test_cln_fp=[]\n",
    "y_test_cln_fp=[]\n",
    "\n",
    "for k in range(len(predictions_cln)):\n",
    "    if(np.argmax(predictions_cln, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_cln_indexes.append(k)\n",
    "    else:\n",
    "        fp_cln_indexes.append(k)\n",
    "\n",
    "for k in tp_cln_indexes:\n",
    "    x_test_cln_tp.append(x_test_cln[k])\n",
    "    y_test_cln_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_cln_indexes:\n",
    "    x_test_cln_fp.append(x_test_cln[k])\n",
    "    y_test_cln_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_cln_tp = np.array(x_test_cln_tp)\n",
    "x_test_cln_fp = np.array(x_test_cln_fp)\n",
    "\n",
    "print('Number of clean true positives: {:}'.format(len(x_test_cln_tp)))\n",
    "print('Number of clean false positives: {:}'.format(len(x_test_cln_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b91dd",
   "metadata": {},
   "source": [
    "Step 3: Craft adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e07528",
   "metadata": {},
   "source": [
    "*Craft Jacobian-based Saliency Map Attack (JSMA) attacks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc57cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack = SaliencyMapMethod(classifier=classifier, theta = 0.1, gamma=0.3, verbose=True)\n",
    "# x_test_JSMA_cifar10 = attack.generate(x_test_cln)\n",
    "# %store x_test_JSMA_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d730b68",
   "metadata": {},
   "source": [
    "*Craft Basic Iterative Method (BMI) attacks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3987b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# attack = BasicIterativeMethod(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# x_test_BIM_cifar10 = attack.generate(x_test_cln)\n",
    "# %store x_test_BIM_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76558c01",
   "metadata": {},
   "source": [
    "*Craft Projected Gradient Descent (PGD) attacks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64259af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack = ProjectedGradientDescent(classifier, eps=0.1, eps_step=0.01, max_iter=30)\n",
    "# x_test_PGD_cifar10 = attack.generate(x_test_cln)\n",
    "# %store x_test_PGD_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2f431",
   "metadata": {},
   "source": [
    "*Craft NewtonFool attacks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack = NewtonFool(classifier=classifier, eta=0.005, max_iter=25, verbose=True)\n",
    "# x_test_Newton_cifar10 = attack.generate(x_test_cln)\n",
    "# %store x_test_Newton_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a5111d",
   "metadata": {},
   "source": [
    "*Craft DeepFool attacks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca35c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attack = DeepFool(classifier=classifier, epsilon=1e-06/255, max_iter=50)\n",
    "# x_test_Deep_cifar10 = attack.generate(x_test_cln)\n",
    "# %store x_test_Deep_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f9891",
   "metadata": {},
   "source": [
    "*Alternatively, load existing adversarial attacks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d6ff9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = 'JSMA'\n",
    "%store -r x_test_JSMA_cifar10\n",
    "x_test_adv = x_test_JSMA_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f4a5f",
   "metadata": {},
   "source": [
    "Step 4: Evaluate the classifier on the adversarial test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee462839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test examples: 1.3%\n"
     ]
    }
   ],
   "source": [
    "predictions_adv = classifier.predict(x_test_adv)\n",
    "accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy_adv * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e6a1c",
   "metadata": {},
   "source": [
    "Step 5: Split the adversarial test set into its true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "214595e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial TP: 130\n",
      "Adversarial FP: 9870\n"
     ]
    }
   ],
   "source": [
    "tp_adv_indexes=[]\n",
    "fp_adv_indexes=[]\n",
    "x_test_adv_tp=[]\n",
    "y_test_adv_tp=[]\n",
    "x_test_adv_fp=[]\n",
    "y_test_adv_fp=[]\n",
    "\n",
    "for k in range(len(predictions_adv)):\n",
    "    if(np.argmax(predictions_adv, axis=1)[k] == np.argmax(y_test_cln, axis=1)[k]):\n",
    "        tp_adv_indexes.append(k)\n",
    "    else:\n",
    "        fp_adv_indexes.append(k)\n",
    "\n",
    "for k in tp_adv_indexes:\n",
    "    x_test_adv_tp.append(x_test_adv[k])\n",
    "    y_test_adv_tp.append(y_test_cln[k])\n",
    "    \n",
    "for k in fp_adv_indexes:\n",
    "    x_test_adv_fp.append(x_test_adv[k])\n",
    "    y_test_adv_fp.append(y_test_cln[k])\n",
    "    \n",
    "x_test_adv_tp = np.array(x_test_adv_tp)\n",
    "x_test_adv_fp = np.array(x_test_adv_fp)\n",
    "\n",
    "print('Adversarial TP: {:}'.format(len(x_test_adv_tp)))\n",
    "print('Adversarial FP: {:}'.format(len(x_test_adv_fp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce3b44",
   "metadata": {},
   "source": [
    "Step 6: Plot clean test examples and their adversarial counterparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb593b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(x_test_cln[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(y_test_cln,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    ax = plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(x_test_adv[i], cmap='gray')\n",
    "    ax.set_title('{:}'.format(np.argmax(predictions_adv,axis=1)[i]))\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a800d61",
   "metadata": {},
   "source": [
    "## **Section 2 - Defence**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d97aeb",
   "metadata": {},
   "source": [
    "### **PixelDefend**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f8fb1",
   "metadata": {},
   "source": [
    "Step 1: Transform input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "737293cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "defence = PixelDefend(eps=16, pixel_cnn=pixelcnn, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147774d2",
   "metadata": {},
   "source": [
    "*Pre-process input for PixelDefend*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12f65345",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln_tp_pre = (np.transpose(x_test_cln_tp, (0, -1, 1, 2))).astype(np.float32)\n",
    "x_test_cln_fp_pre = (np.transpose(x_test_cln_fp, (0, -1, 1, 2))).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "072deb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_tp_pre = (np.transpose(x_test_adv_tp, (0, -1, 1, 2))).astype(np.float32)\n",
    "x_test_adv_fp_pre = (np.transpose(x_test_adv_fp, (0, -1, 1, 2))).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6508a6",
   "metadata": {},
   "source": [
    "*Transform input*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2aec3ba8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 134217728 bytes. Buy new RAM!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-47ad86257c3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_test_cln_tp_pre_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_cln_tp_pre\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_test_cln_fp_pre_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_cln_fp_pre\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_test_cln_pre_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_cln_tp_pre_pd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_cln_fp_pre_pd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test_cln_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test_cln_tp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my_test_cln_fp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\art\\defences\\preprocessor\\pixel_defend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0moriginal_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpixel_cnn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpixel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mactivations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\art\\estimators\\classification\\pytorch.py\u001b[0m in \u001b[0;36mget_activations\u001b[1;34m(self, x, layer, batch_size, framework)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[1;31m# Run prediction for the current batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\art\\estimators\\classification\\pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m                         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m                             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    945\u001b[0m                             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a6b8641203bd>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# [batch_size, 2h, 32, 32]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskBConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# [batch_size, 3x256, 32, 32]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-9088318889eb>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;34m\"\"\"Residual connection\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:75] data. DefaultCPUAllocator: not enough memory: you tried to allocate 134217728 bytes. Buy new RAM!"
     ]
    }
   ],
   "source": [
    "x_test_cln_tp_pre_pd = defence(x_test_cln_tp_pre * 255)[0] / 255\n",
    "x_test_cln_fp_pre_pd = defence(x_test_cln_fp_pre * 255)[0] / 255\n",
    "x_test_cln_pre_pd = np.concatenate((x_test_cln_tp_pre_pd, x_test_cln_fp_pre_pd), axis=0)\n",
    "y_test_cln_pd = y_test_cln_tp + y_test_cln_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_tp_pre_pd = defence(x_test_adv_tp_pre * 255)[0] / 255\n",
    "x_test_adv_fp_pre_pd = defence(x_test_adv_fp_pre * 255)[0] / 255\n",
    "x_test_adv_pre_pd = np.concatenate((x_test_adv_tp_pre_pd, x_test_adv_fp_pre_pd), axis=0)\n",
    "y_test_adv_pd = y_test_adv_tp + y_test_adv_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bd636",
   "metadata": {},
   "source": [
    "*Post-process output for classification and plotting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ac2156",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cln_pd = np.transpose(x_test_cln_pre_pd, (0, 2, -1, 1))\n",
    "x_test_cln_tp_pd = np.transpose(x_test_cln_tp_pre_pd, (0, 2, -1, 1))\n",
    "x_test_cln_fp_pd = np.transpose(x_test_cln_fp_pre_pd, (0, 2, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv_pd = np.transpose(x_test_adv_pre_pd, (0, 2, -1, 1))\n",
    "x_test_adv_tp_pd = np.transpose(x_test_adv_tp_pre_pd, (0, 2, -1, 1))\n",
    "x_test_adv_fp_pd = np.transpose(x_test_adv_fp_pre_pd, (0, 2, -1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9f6b8",
   "metadata": {},
   "source": [
    "Step 2: Evaluate the classifier on all 4 sets of data after PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ab56c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions_cln_pd = classifier.predict(x_test_cln_pd)\n",
    "accuracy_cln_pd = np.sum(np.argmax(predictions_cln_pd, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"Effect of PixelDefend on entire clean test set: {:.2f}%\".format((accuracy_cln_pd - accuracy_cln) * 100))\n",
    " \n",
    "predictions_cln_tp_pd = classifier.predict(x_test_cln_tp_pd)\n",
    "accuracy_cln_tp_pd = np.sum(np.argmax(predictions_cln_tp_pd, axis=1) == np.argmax(y_test_cln_tp, axis=1)) / len(y_test_cln_tp)\n",
    "\n",
    "# print(\"\\nAccuracy on true positive clean test examples after PixelDefend: {:.2f}%\".format(accuracy_cln_tp_pd * 100))\n",
    "print(\"\\nAccuracy drop on true positive clean test examples after PixelDefend: {:.2f}%\".format((1 - accuracy_cln_tp_pd) * 100))\n",
    "\n",
    "predictions_cln_fp_pd = classifier.predict(x_test_cln_fp_pd)\n",
    "accuracy_cln_fp_pd = np.sum(np.argmax(predictions_cln_fp_pd, axis=1) == np.argmax(y_test_cln_fp, axis=1)) / len(y_test_cln_fp)\n",
    "\n",
    "print(\"\\nAccuracy increase on false positive clean test examples after PixelDefend: {:.2f}%\".format(accuracy_cln_fp_pd * 100))\n",
    "\n",
    "predictions_adv_pd = classifier.predict(x_test_adv_pd)\n",
    "accuracy_adv_pd = np.sum(np.argmax(predictions_adv_pd, axis=1) == np.argmax(y_test_cln, axis=1)) / len(y_test_cln)\n",
    "\n",
    "print(\"\\nEffect of PixelDefend on entire adversarial test set: {:.2f}%\".format((accuracy_adv_pd-accuracy_adv) * 100))\n",
    "\n",
    "predictions_adv_tp_pd = classifier.predict(x_test_adv_tp_pd)\n",
    "accuracy_adv_tp_pd = np.sum(np.argmax(predictions_adv_tp_pd, axis=1) == np.argmax(y_test_adv_tp, axis=1)) / len(y_test_adv_tp)\n",
    "\n",
    "# print(\"\\nAccuracy on true positive adversarial test examples after PixelDefend: {:.2f}%\".format(accuracy_adv_tp_pd * 100))\n",
    "print(\"\\nAccuracy drop on true positive adversarial test examples after PixelDefend: {:.2f}%\".format((1 - accuracy_adv_tp_pd) * 100))\n",
    "\n",
    "predictions_adv_fp_pd = classifier.predict(x_test_adv_fp_pd)\n",
    "accuracy_adv_fp_pd = np.sum(np.argmax(predictions_adv_fp_pd, axis=1) == np.argmax(y_test_adv_fp, axis=1)) / len(y_test_adv_fp)\n",
    "\n",
    "print(\"\\nAccuracy increase on false positive adversarial test examples after PixelDefend: {:.2f}%\".format(accuracy_adv_fp_pd * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8236f2",
   "metadata": {},
   "source": [
    "Step 3: Plot all data pre- and post-transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee10bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot images\n",
    "predictions_cln_tp = classifier.predict(x_test_cln_tp)\n",
    "predictions_cln_fp = classifier.predict(x_test_cln_fp)\n",
    "predictions_adv_tp = classifier.predict(x_test_adv_tp)\n",
    "predictions_adv_fp = classifier.predict(x_test_adv_fp)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "#Plot clean true positives\n",
    "ax = plt.subplot(4, 2, 2*0+1)\n",
    "plt.imshow(x_test_cln_tp[0], cmap='gray')\n",
    "ax.set_title('Clean TP: {:}'.format(np.argmax(predictions_cln_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*0+2)\n",
    "plt.imshow(x_test_cln_tp_pd[0], cmap='gray')\n",
    "ax.set_title('Clean TP after PixelDefend: {:}'.format(np.argmax(predictions_cln_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot clean false positives\n",
    "ax = plt.subplot(4, 2, 2*1+1)\n",
    "plt.imshow(x_test_cln_fp[0], cmap='gray')\n",
    "ax.set_title('Clean FP: {:}\\nTrue class: {:}'.format(np.argmax(predictions_cln_fp,axis=1)[0], np.argmax(y_test_cln_fp,axis=1)[0]), fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*1+2)\n",
    "plt.imshow(x_test_cln_fp_pd[0], cmap='gray')\n",
    "ax.set_title('Clean FP after PixelDefend: {:}\\nTrue class: {:}'.format(np.argmax(predictions_cln_fp_pd,axis=1)[0], np.argmax(y_test_cln_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot adversarial true positives\n",
    "ax = plt.subplot(4, 2, 2*2+1)\n",
    "plt.imshow(x_test_adv_tp[0], cmap='gray')\n",
    "ax.set_title('Adversarial TP: {:}'.format(np.argmax(predictions_adv_tp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*2+2)\n",
    "plt.imshow(x_test_adv_tp_pd[0], cmap='gray')\n",
    "ax.set_title('Adversarial TP after PixelDefend: {:}'.format(np.argmax(predictions_adv_tp_pd,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "#Plot adversarial false positivies\n",
    "ax = plt.subplot(4, 2, 2*3+1)\n",
    "plt.imshow(x_test_adv_fp[0], cmap='gray')\n",
    "ax.set_title('Adversarial FP: {:}\\nTrue class: {:}'.format(np.argmax(predictions_adv_fp,axis=1)[0], np.argmax(y_test_adv_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "ax = plt.subplot(4, 2, 2*3+2)\n",
    "plt.imshow(x_test_adv_fp_pd[0], cmap='gray')\n",
    "ax.set_title('Adversarial FP after PixelDefend: {:}\\nTrue class: {:}'.format(np.argmax(predictions_adv_fp_pd,axis=1)[0], np.argmax(y_test_adv_fp,axis=1)[0]))\n",
    "plt.axis(\"off\")\n",
    "    \n",
    "image_path = '/home/cyber/Desktop/Adrian/Plots/PixelDefend_CIFAR-10_{:}.png'.format(attack_name)\n",
    "plt.savefig(image_path, dpi=500, transparent=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21800af9",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c630",
   "metadata": {},
   "source": [
    "Optional step: Compare the performance of PixelDefend against the adversary over a range of eps values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_range = [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# accuracy_original = []\n",
    "# accuracy_robust = []\n",
    "\n",
    "# attack = FastGradientMethod(classifier)\n",
    "# attack_robust = FastGradientMethod(robust_classifier)\n",
    "\n",
    "# for eps in eps_range:\n",
    "#     attack.set_params(**{'eps': eps})\n",
    "#     attack_robust.set_params(**{'eps': eps})\n",
    "#     x_test_adv = attack.generate(x_test[:100])\n",
    "#     x_test_adv_robust = attack_robust.generate(x_test[:100])\n",
    "    \n",
    "#     predictions_original = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "#     accuracy_original += [np.sum(predictions_original == np.argmax(y_test[:100], axis=1))]\n",
    "    \n",
    "#     predictions_robust = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "#     accuracy_robust += [np.sum(predictions_robust == np.argmax(y_test[:100], axis=1))]\n",
    "\n",
    "# eps_range = eps_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8cbbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(np.array(eps_range), np.array(accuracy_original), 'b--', label='Original classifier')\n",
    "# ax.plot(np.array(eps_range), np.array(accuracy_robust), 'r--', label='Robust classifier')\n",
    "\n",
    "# legend = ax.legend(loc='upper right', shadow=True, fontsize='large')\n",
    "# #legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "# plt.xlabel('Attack strength (eps)')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09a11c",
   "metadata": {},
   "source": [
    "## PixelCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3078815",
   "metadata": {},
   "source": [
    "### Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_mask(width, height, starting_point):\n",
    "    row_grid, col_grid = np.meshgrid(np.arange(width), np.arange(height), indexing='ij')\n",
    "    mask = np.logical_or(\n",
    "        row_grid < starting_point[0],\n",
    "        np.logical_and(row_grid == starting_point[0], col_grid <= starting_point[1]))\n",
    "    return mask\n",
    "\n",
    "def conv_mask(width, height, include_center=False):\n",
    "    return 1.0 * causal_mask(width, height, starting_point=(width//2, height//2 + include_center - 1))\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        _, n_channels, width, height = self.weight.size()\n",
    "\n",
    "        mask = conv_mask(width, height, include_center=mask_type=='B')\n",
    "        self.register_buffer('mask', torch.from_numpy(mask).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bee7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    n_channels = 4\n",
    "    kernel_size = 7\n",
    "    padding = 3\n",
    "    n_pixels_out = 2 # binary 0/1 pixels\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            MaskedConv2d('A', in_channels=1, out_channels=self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            MaskedConv2d('B', self.n_channels, self.n_channels, kernel_size=self.kernel_size, padding=self.padding, bias=False), nn.BatchNorm2d(self.n_channels), nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=self.n_channels, out_channels=self.n_pixels_out, kernel_size=1)\n",
    "        )\n",
    "        self.fc = nn.Linear(28*28, 28*28*64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        logit_output = self.fc(x)\n",
    "        logit_output = logit_output.view(-1, 64, 1, 28, 28)\n",
    "\n",
    "        return logit_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25319c6a",
   "metadata": {},
   "source": [
    "### Attempt 2: PixelCNN by Jzbontar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b17c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e0ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('torch.cuda.is_available():', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ee6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from torch import nn, optim, cuda, backends\n",
    "from torch.utils import data\n",
    "backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv2d, self).__init__(*args, **kwargs)\n",
    "        assert mask_type in {'A', 'B'}\n",
    "        self.register_buffer('mask', self.weight.data.clone())\n",
    "        _, _, kH, kW = self.weight.size()\n",
    "        self.mask.fill_(1)\n",
    "        self.mask[:, :, kH // 2, kW // 2 + (mask_type == 'B'):] = 0\n",
    "        self.mask[:, :, kH // 2 + 1:] = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv2d, self).forward(x)\n",
    "\n",
    "fm = 64\n",
    "model = nn.Sequential(\n",
    "    MaskedConv2d('A', 1,  fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    MaskedConv2d('B', fm, fm, 7, 1, 3, bias=False), nn.BatchNorm2d(fm), nn.ReLU(True),\n",
    "    nn.Conv2d(fm, 256, 1))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "\n",
    "tr = data.DataLoader(datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "                     batch_size=128, shuffle=True, num_workers=1, pin_memory=True)\n",
    "te = data.DataLoader(datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor()),\n",
    "                     batch_size=128, shuffle=False, num_workers=1, pin_memory=True)\n",
    "sample = torch.Tensor(144, 1, 28, 28).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# for epoch in range(5):\n",
    "#     # train\n",
    "#     err_tr = []\n",
    "#     cuda.synchronize()\n",
    "#     time_tr = time.time()\n",
    "#     model.train(True)\n",
    "#     for input, _ in tr:\n",
    "#         input = Variable(input.cuda(non_blocking=True))\n",
    "#         target = Variable((input.data[:,0] * 255).long())\n",
    "#         loss = F.cross_entropy(model(input), target)\n",
    "#         err_tr.append(loss.data.item())\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     cuda.synchronize()\n",
    "#     time_tr = time.time() - time_tr\n",
    "\n",
    "#     # compute error on test set\n",
    "#     err_te = []\n",
    "#     cuda.synchronize()\n",
    "#     time_te = time.time()\n",
    "#     model.train(False)\n",
    "#     for input, _ in te:\n",
    "#         input = Variable(input.cuda(non_blocking=True), volatile=True)\n",
    "#         target = Variable((input.data[:,0] * 255).long())\n",
    "#         loss = F.cross_entropy(model(input), target)\n",
    "#         err_te.append(loss.data.item())\n",
    "#     cuda.synchronize()\n",
    "#     time_te = time.time() - time_te\n",
    "\n",
    "#     # sample\n",
    "#     sample.fill_(0)\n",
    "#     model.train(False)\n",
    "#     for i in range(28):\n",
    "#         for j in range(28):\n",
    "#             out = model(Variable(sample, volatile=True))\n",
    "#             probs = F.softmax(out[:, :, i, j]).data\n",
    "#             sample[:, :, i, j] = torch.multinomial(probs, 1).float() / 255.\n",
    "#     utils.save_image(sample, 'sample_{:02d}.png'.format(epoch), nrow=12, padding=0)\n",
    "\n",
    "#     print('epoch={}; nll_tr={:.7f}; nll_te={:.7f}; time_tr={:.1f}s; time_te={:.1f}s'.format(\n",
    "#         epoch, np.mean(err_tr), np.mean(err_te), time_tr, time_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64925eb5",
   "metadata": {},
   "source": [
    "### Attempt 3: PixelCNN by Kamenbliznashki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4dd390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PixelCNN implementation\n",
    "References:\n",
    "    1. van den Oord, Pixel Recurrent Neural Networks 2016a\n",
    "    2. van den Oord, Conditional Image Generation with PixelCNN Decoders, 2016c\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "image_dims=(1,32,32) \n",
    "n_bits=4\n",
    "n_channels=128\n",
    "n_out_conv_channels=1024\n",
    "kernel_size=5\n",
    "n_res_layers=12\n",
    "n_cond_classes=10\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Model components\n",
    "# --------------------\n",
    "\n",
    "def pixelcnn_gate(x):\n",
    "    a, b = x.chunk(2,1)\n",
    "    return torch.tanh(a) * torch.sigmoid(b)\n",
    "\n",
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, *args, mask_type=None, mask_n_channels=None, gated=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "#         nn.init.constant_(bias, 0.)\n",
    "\n",
    "        # set up mask -- cf PixelRNN paper Figure 2 Right: masks A and B\n",
    "        mask_type = mask_type\n",
    "        mask_n_channels = mask_n_channels\n",
    "        center_row = kernel_size[0] // 2\n",
    "        center_col = kernel_size[1] // 2\n",
    "\n",
    "        mask = torch.ones_like(weight)         # shape (out_channels, in_channels, kernel_height, kernel_width)\n",
    "\n",
    "        # mask out 1/ rows below the middle and 2/ center row pixels right of middle\n",
    "        if center_row == 0:                         # case when kernel_size = (1,k) in horizontal stack\n",
    "            mask[:, :, :, center_col+1:] = 0\n",
    "        elif center_col == 0:                       # case when kernel_size = (k,1)\n",
    "            mask[:, :, center_row+1:, :] = 0\n",
    "        else:                                       # case when kernel_size = (k,k)\n",
    "            mask[:, :, center_row+1:, :] = 0\n",
    "            mask[:, :, center_row, center_col+1:] = 0\n",
    "\n",
    "        # mask out center pixel in future channels -- mask A current channel is 0; mask B current channel is 1\n",
    "        for i in range(mask_n_channels):\n",
    "            for j in range(mask_n_channels):\n",
    "                if (mask_type=='a' and i >= j) or (mask_type=='b' and i > j):\n",
    "                    mask[j::mask_n_channels, i::mask_n_channels, center_row, center_col] = 0\n",
    "\n",
    "        # mask out center row (vertical stack in a Gated Residual Layer); cf Conditional image generation with PixelCNN Decoders\n",
    "        if mask_type == 'vstack':\n",
    "            mask[:, :, center_row, :] = 0\n",
    "\n",
    "        if gated:\n",
    "            # pixelcnn gate splits the input in two along the channel dim;\n",
    "            # ensure that both chunks receive the same mask by replicating the first half of the mask over the second\n",
    "            mask = mask.chunk(2,0)[0].repeat(2,1,1,1)\n",
    "\n",
    "        # final mask\n",
    "        register_buffer('mask', mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight.data *= mask\n",
    "        return super().forward(x)\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = super().__repr__()\n",
    "        return s[:-1] + ', mask_type={}, mask_n_channels={}'.format(mask_type, mask_n_channels) + s[-1]\n",
    "\n",
    "\n",
    "class GatedResidualLayer(nn.Module):\n",
    "    \"\"\" Figure 2 in Conditional image generation with PixelCNN Decoders \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, mask_type, mask_n_channels, n_cond_classes, norm_layer):\n",
    "        super().__init__()\n",
    "        residual = (in_channels==out_channels)\n",
    "        norm_layer = norm_layer\n",
    "\n",
    "        v   = MaskedConv2d(in_channels, 2*out_channels, kernel_size, padding=kernel_size//2,\n",
    "                                mask_type='vstack', mask_n_channels=mask_n_channels, gated=True)\n",
    "        h   = MaskedConv2d(in_channels, 2*out_channels, (1, kernel_size), padding=(0, kernel_size//2),\n",
    "                                mask_type=mask_type, mask_n_channels=mask_n_channels, gated=True)\n",
    "        v2h = MaskedConv2d(2*out_channels, 2*out_channels, kernel_size=1,\n",
    "                                mask_type=mask_type, mask_n_channels=mask_n_channels, gated=True)\n",
    "        h2h = MaskedConv2d(out_channels, out_channels, kernel_size=1,\n",
    "                                mask_type=mask_type, mask_n_channels=mask_n_channels, gated=False)\n",
    "\n",
    "        if n_cond_classes:\n",
    "            proj_h = nn.Linear(n_cond_classes, 2*out_channels)\n",
    "\n",
    "        if norm_layer:\n",
    "            norm_layer_v = nn.BatchNorm2d(out_channels)\n",
    "            norm_layer_h = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x_v, x_h, h=None):\n",
    "        # projection of h if included for conditional generation (cf paper section 2.3 -- added before the pixelcnn_gate)\n",
    "        proj_y = proj_h(h)[:,:,None,None] if h is not None else 0\n",
    "\n",
    "        # vertical stack\n",
    "        x_v_out = v(x_v)\n",
    "        x_v2h = v2h(x_v_out) + proj_y\n",
    "        x_v_out = pixelcnn_gate(x_v_out)\n",
    "\n",
    "        # horizontal stack\n",
    "        x_h_out = h(x_h) + x_v2h + proj_y\n",
    "        x_h_out = pixelcnn_gate(x_h_out)\n",
    "        x_h_out = h2h(x_h_out)\n",
    "\n",
    "        # residual connection\n",
    "        if residual:\n",
    "            x_h_out = x_h_out + x_h\n",
    "\n",
    "        # normalization\n",
    "        if norm_layer:\n",
    "            x_v_out = norm_layer_v(x_v_out)\n",
    "            x_h_out = norm_layer_h(x_h_out)\n",
    "\n",
    "        return x_v_out, x_h_out\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'residual={}, norm_layer={}'.format(residual, norm_layer)\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# PixelCNN\n",
    "# --------------------\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, image_dims, n_bits, n_channels, n_out_conv_channels, kernel_size, n_res_layers, n_cond_classes, norm_layer=True):\n",
    "        super().__init__()\n",
    "        C, H, W = image_dims\n",
    "\n",
    "        input_conv = MaskedConv2d(C, 2*n_channels, kernel_size=7, padding=3, mask_type='a', mask_n_channels=C, gated=True)\n",
    "        res_layers = nn.ModuleList([\n",
    "            GatedResidualLayer(n_channels, n_channels, kernel_size, 'b', C, n_cond_classes, norm_layer)\n",
    "            for _ in range(n_res_layers)])\n",
    "        conv_out1 = MaskedConv2d(n_channels, 2*n_out_conv_channels, kernel_size=1, mask_type='b', mask_n_channels=C, gated=True)\n",
    "        conv_out2 = MaskedConv2d(n_out_conv_channels, 2*n_out_conv_channels, kernel_size=1, mask_type='b', mask_n_channels=C, gated=True)\n",
    "        output = MaskedConv2d(n_out_conv_channels, C * 2**n_bits, kernel_size=1, mask_type='b', mask_n_channels=C)\n",
    "\n",
    "        if n_cond_classes:\n",
    "            proj_h = nn.Linear(n_cond_classes, 2*n_channels)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        x = pixelcnn_gate(input_conv(x) + (proj_h(h)[:,:,None,None] if h is not None else 0.))\n",
    "        x_v, x_h = x, x\n",
    "\n",
    "        for l in res_layers:\n",
    "            x_v, x_h = l(x_v, x_h)\n",
    "\n",
    "        out = pixelcnn_gate(conv_out1(x_h))\n",
    "        out = pixelcnn_gate(conv_out2(out))\n",
    "        out = output(out)\n",
    "\n",
    "        return out.reshape(B, -1, C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ddf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN(image_dims=(3,32,32), n_bits=4, n_channels=128, n_out_conv_channels=1024, kernel_size=5, n_res_layers=12, n_cond_classes=10)\n",
    "# model.load_state_dict(torch.load('/home/cyber/miniconda3/envs/tf-gpu/pixel_models-master/results/pixelcnn/2021-05-04_08-44-00/checkpoint.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ec8c9",
   "metadata": {},
   "source": [
    "### Attempt 4: PixelCNN by pclucas14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbac22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concat_elu(x):\n",
    "    \"\"\" like concatenated ReLU (http://arxiv.org/abs/1603.05201), but then with ELU \"\"\"\n",
    "    # Pytorch ordering\n",
    "    axis = len(x.size()) - 3\n",
    "    return F.elu(torch.cat([x, -x], dim=axis))\n",
    "\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    \"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"\n",
    "    # TF ordering\n",
    "    axis  = len(x.size()) - 1\n",
    "    m, _  = torch.max(x, dim=axis)\n",
    "    m2, _ = torch.max(x, dim=axis, keepdim=True)\n",
    "    return m + torch.log(torch.sum(torch.exp(x - m2), dim=axis))\n",
    "\n",
    "\n",
    "def log_prob_from_logits(x):\n",
    "    \"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"\n",
    "    # TF ordering\n",
    "    axis = len(x.size()) - 1\n",
    "    m, _ = torch.max(x, dim=axis, keepdim=True)\n",
    "    return x - m - torch.log(torch.sum(torch.exp(x - m), dim=axis, keepdim=True))\n",
    "\n",
    "\n",
    "def discretized_mix_logistic_loss(x, l):\n",
    "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
    "    # Pytorch ordering\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    l = l.permute(0, 2, 3, 1)\n",
    "    xs = [int(y) for y in x.size()]\n",
    "    ls = [int(y) for y in l.size()]\n",
    "   \n",
    "    # here and below: unpacking the params of the mixture of logistics\n",
    "    nr_mix = int(ls[-1] / 10) \n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3]) # 3 for mean, scale, coef\n",
    "    means = l[:, :, :, :, :nr_mix]\n",
    "    # log_scales = torch.max(l[:, :, :, :, nr_mix:2 * nr_mix], -7.)\n",
    "    log_scales = torch.clamp(l[:, :, :, :, nr_mix:2 * nr_mix], min=-7.)\n",
    "   \n",
    "    coeffs = F.tanh(l[:, :, :, :, 2 * nr_mix:3 * nr_mix])\n",
    "    # here and below: getting the means and adjusting them based on preceding\n",
    "    # sub-pixels\n",
    "    x = x.contiguous()\n",
    "    x = x.unsqueeze(-1) + Variable(torch.zeros(xs + [nr_mix]).cuda(), requires_grad=False)\n",
    "    m2 = (means[:, :, :, 1, :] + coeffs[:, :, :, 0, :]\n",
    "                * x[:, :, :, 0, :]).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
    "\n",
    "    m3 = (means[:, :, :, 2, :] + coeffs[:, :, :, 1, :] * x[:, :, :, 0, :] +\n",
    "                coeffs[:, :, :, 2, :] * x[:, :, :, 1, :]).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
    "\n",
    "    means = torch.cat((means[:, :, :, 0, :].unsqueeze(3), m2, m3), dim=3)\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = F.sigmoid(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = F.sigmoid(min_in)\n",
    "    # log probability for edge case of 0 (before scaling)\n",
    "    log_cdf_plus = plus_in - F.softplus(plus_in)\n",
    "    # log probability for edge case of 255 (before scaling)\n",
    "    log_one_minus_cdf_min = -F.softplus(min_in)\n",
    "    cdf_delta = cdf_plus - cdf_min  # probability for all other cases\n",
    "    mid_in = inv_stdv * centered_x\n",
    "    # log probability in the center of the bin, to be used in extreme cases\n",
    "    # (not actually used in our code)\n",
    "    log_pdf_mid = mid_in - log_scales - 2. * F.softplus(mid_in)\n",
    "\n",
    "    # now select the right output: left edge case, right edge case, normal\n",
    "    # case, extremely low prob case (doesn't actually happen for us)\n",
    "\n",
    "    # this is what we are really doing, but using the robust version below for extreme cases in other applications and to avoid NaN issue with tf.select()\n",
    "    # log_probs = tf.select(x < -0.999, log_cdf_plus, tf.select(x > 0.999, log_one_minus_cdf_min, tf.log(cdf_delta)))\n",
    "\n",
    "    # robust version, that still works if probabilities are below 1e-5 (which never happens in our code)\n",
    "    # tensorflow backpropagates through tf.select() by multiplying with zero instead of selecting: this requires use to use some ugly tricks to avoid potential NaNs\n",
    "    # the 1e-12 in tf.maximum(cdf_delta, 1e-12) is never actually used as output, it's purely there to get around the tf.select() gradient issue\n",
    "    # if the probability on a sub-pixel is below 1e-5, we use an approximation\n",
    "    # based on the assumption that the log-density is constant in the bin of\n",
    "    # the observed sub-pixel value\n",
    "    \n",
    "    inner_inner_cond = (cdf_delta > 1e-5).float()\n",
    "    inner_inner_out  = inner_inner_cond * torch.log(torch.clamp(cdf_delta, min=1e-12)) + (1. - inner_inner_cond) * (log_pdf_mid - np.log(127.5))\n",
    "    inner_cond       = (x > 0.999).float()\n",
    "    inner_out        = inner_cond * log_one_minus_cdf_min + (1. - inner_cond) * inner_inner_out\n",
    "    cond             = (x < -0.999).float()\n",
    "    log_probs        = cond * log_cdf_plus + (1. - cond) * inner_out\n",
    "    log_probs        = torch.sum(log_probs, dim=3) + log_prob_from_logits(logit_probs)\n",
    "    \n",
    "    return -torch.sum(log_sum_exp(log_probs))\n",
    "\n",
    "\n",
    "def discretized_mix_logistic_loss_1d(x, l):\n",
    "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
    "    # Pytorch ordering\n",
    "    x = x.permute(0, 2, 3, 1)\n",
    "    l = l.permute(0, 2, 3, 1)\n",
    "    xs = [int(y) for y in x.size()]\n",
    "    ls = [int(y) for y in l.size()]\n",
    "\n",
    "    # here and below: unpacking the params of the mixture of logistics\n",
    "    nr_mix = int(ls[-1] / 3)\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 2]) # 2 for mean, scale\n",
    "    means = l[:, :, :, :, :nr_mix]\n",
    "    log_scales = torch.clamp(l[:, :, :, :, nr_mix:2 * nr_mix], min=-7.)\n",
    "    # here and below: getting the means and adjusting them based on preceding\n",
    "    # sub-pixels\n",
    "    x = x.contiguous()\n",
    "    x = x.unsqueeze(-1) + Variable(torch.zeros(xs + [nr_mix]).cuda(), requires_grad=False)\n",
    "\n",
    "    # means = torch.cat((means[:, :, :, 0, :].unsqueeze(3), m2, m3), dim=3)\n",
    "    centered_x = x - means\n",
    "    inv_stdv = torch.exp(-log_scales)\n",
    "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
    "    cdf_plus = F.sigmoid(plus_in)\n",
    "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
    "    cdf_min = F.sigmoid(min_in)\n",
    "    # log probability for edge case of 0 (before scaling)\n",
    "    log_cdf_plus = plus_in - F.softplus(plus_in)\n",
    "    # log probability for edge case of 255 (before scaling)\n",
    "    log_one_minus_cdf_min = -F.softplus(min_in)\n",
    "    cdf_delta = cdf_plus - cdf_min  # probability for all other cases\n",
    "    mid_in = inv_stdv * centered_x\n",
    "    # log probability in the center of the bin, to be used in extreme cases\n",
    "    # (not actually used in our code)\n",
    "    log_pdf_mid = mid_in - log_scales - 2. * F.softplus(mid_in)\n",
    "    \n",
    "    inner_inner_cond = (cdf_delta > 1e-5).float()\n",
    "    inner_inner_out  = inner_inner_cond * torch.log(torch.clamp(cdf_delta, min=1e-12)) + (1. - inner_inner_cond) * (log_pdf_mid - np.log(127.5))\n",
    "    inner_cond       = (x > 0.999).float()\n",
    "    inner_out        = inner_cond * log_one_minus_cdf_min + (1. - inner_cond) * inner_inner_out\n",
    "    cond             = (x < -0.999).float()\n",
    "    log_probs        = cond * log_cdf_plus + (1. - cond) * inner_out\n",
    "    log_probs        = torch.sum(log_probs, dim=3) + log_prob_from_logits(logit_probs)\n",
    "    \n",
    "    return -torch.sum(log_sum_exp(log_probs))\n",
    "\n",
    "\n",
    "def to_one_hot(tensor, n, fill_with=1.):\n",
    "    # we perform one hot encore with respect to the last axis\n",
    "    one_hot = torch.FloatTensor(tensor.size() + (n,)).zero_()\n",
    "    if tensor.is_cuda : one_hot = one_hot.cuda()\n",
    "    one_hot.scatter_(len(tensor.size()), tensor.unsqueeze(-1), fill_with)\n",
    "    return Variable(one_hot)\n",
    "\n",
    "\n",
    "def sample_from_discretized_mix_logistic_1d(l, nr_mix):\n",
    "    # Pytorch ordering\n",
    "    l = l.permute(0, 2, 3, 1)\n",
    "    ls = [int(y) for y in l.size()]\n",
    "    xs = ls[:-1] + [1] #[3]\n",
    "\n",
    "    # unpack parameters\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 2]) # for mean, scale\n",
    "\n",
    "    # sample mixture indicator from softmax\n",
    "    temp = torch.FloatTensor(logit_probs.size())\n",
    "    if l.is_cuda : temp = temp.cuda()\n",
    "    temp.uniform_(1e-5, 1. - 1e-5)\n",
    "    temp = logit_probs.data - torch.log(- torch.log(temp))\n",
    "    _, argmax = temp.max(dim=3)\n",
    "   \n",
    "    one_hot = to_one_hot(argmax, nr_mix)\n",
    "    sel = one_hot.view(xs[:-1] + [1, nr_mix])\n",
    "    # select logistic parameters\n",
    "    means = torch.sum(l[:, :, :, :, :nr_mix] * sel, dim=4) \n",
    "    log_scales = torch.clamp(torch.sum(\n",
    "        l[:, :, :, :, nr_mix:2 * nr_mix] * sel, dim=4), min=-7.)\n",
    "    u = torch.FloatTensor(means.size())\n",
    "    if l.is_cuda : u = u.cuda()\n",
    "    u.uniform_(1e-5, 1. - 1e-5)\n",
    "    u = Variable(u)\n",
    "    x = means + torch.exp(log_scales) * (torch.log(u) - torch.log(1. - u))\n",
    "    x0 = torch.clamp(torch.clamp(x[:, :, :, 0], min=-1.), max=1.)\n",
    "    out = x0.unsqueeze(1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def sample_from_discretized_mix_logistic(l, nr_mix):\n",
    "    # Pytorch ordering\n",
    "    l = l.permute(0, 2, 3, 1)\n",
    "    ls = [int(y) for y in l.size()]\n",
    "    xs = ls[:-1] + [3]\n",
    "\n",
    "    # unpack parameters\n",
    "    logit_probs = l[:, :, :, :nr_mix]\n",
    "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3])\n",
    "    # sample mixture indicator from softmax\n",
    "    temp = torch.FloatTensor(logit_probs.size())\n",
    "    if l.is_cuda : temp = temp.cuda()\n",
    "    temp.uniform_(1e-5, 1. - 1e-5)\n",
    "    temp = logit_probs.data - torch.log(- torch.log(temp))\n",
    "    _, argmax = temp.max(dim=3)\n",
    "   \n",
    "    one_hot = to_one_hot(argmax, nr_mix)\n",
    "    sel = one_hot.view(xs[:-1] + [1, nr_mix])\n",
    "    # select logistic parameters\n",
    "    means = torch.sum(l[:, :, :, :, :nr_mix] * sel, dim=4) \n",
    "    log_scales = torch.clamp(torch.sum(\n",
    "        l[:, :, :, :, nr_mix:2 * nr_mix] * sel, dim=4), min=-7.)\n",
    "    coeffs = torch.sum(F.tanh(\n",
    "        l[:, :, :, :, 2 * nr_mix:3 * nr_mix]) * sel, dim=4)\n",
    "    # sample from logistic & clip to interval\n",
    "    # we don't actually round to the nearest 8bit value when sampling\n",
    "    u = torch.FloatTensor(means.size())\n",
    "    if l.is_cuda : u = u.cuda()\n",
    "    u.uniform_(1e-5, 1. - 1e-5)\n",
    "    u = Variable(u)\n",
    "    x = means + torch.exp(log_scales) * (torch.log(u) - torch.log(1. - u))\n",
    "    x0 = torch.clamp(torch.clamp(x[:, :, :, 0], min=-1.), max=1.)\n",
    "    x1 = torch.clamp(torch.clamp(\n",
    "       x[:, :, :, 1] + coeffs[:, :, :, 0] * x0, min=-1.), max=1.)\n",
    "    x2 = torch.clamp(torch.clamp(\n",
    "       x[:, :, :, 2] + coeffs[:, :, :, 1] * x0 + coeffs[:, :, :, 2] * x1, min=-1.), max=1.)\n",
    "\n",
    "    out = torch.cat([x0.view(xs[:-1] + [1]), x1.view(xs[:-1] + [1]), x2.view(xs[:-1] + [1])], dim=3)\n",
    "    # put back in Pytorch ordering\n",
    "    out = out.permute(0, 3, 1, 2)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "''' utilities for shifting the image around, efficient alternative to masking convolutions '''\n",
    "def down_shift(x, pad=None):\n",
    "    # Pytorch ordering\n",
    "    xs = [int(y) for y in x.size()]\n",
    "    # when downshifting, the last row is removed \n",
    "    x = x[:, :, :xs[2] - 1, :]\n",
    "    # padding left, padding right, padding top, padding bottom\n",
    "    pad = nn.ZeroPad2d((0, 0, 1, 0)) if pad is None else pad\n",
    "    return pad(x)\n",
    "\n",
    "\n",
    "def right_shift(x, pad=None):\n",
    "    # Pytorch ordering\n",
    "    xs = [int(y) for y in x.size()]\n",
    "    # when righshifting, the last column is removed \n",
    "    x = x[:, :, :, :xs[3] - 1]\n",
    "    # padding left, padding right, padding top, padding bottom\n",
    "    pad = nn.ZeroPad2d((1, 0, 0, 0)) if pad is None else pad\n",
    "    return pad(x)\n",
    "\n",
    "\n",
    "def load_part_of_model(model, path):\n",
    "    params = torch.load(path)\n",
    "    added = 0\n",
    "    for name, param in params.items():\n",
    "        if name in model.state_dict().keys():\n",
    "            try : \n",
    "                model.state_dict()[name].copy_(param)\n",
    "                added += 1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    print('added %s of params:' % (added / float(len(model.state_dict().keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedf8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nin(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(nin, self).__init__()\n",
    "        self.lin_a = wn(nn.Linear(dim_in, dim_out))\n",
    "        self.dim_out = dim_out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        og_x = x\n",
    "        # assumes pytorch ordering\n",
    "        \"\"\" a network in network layer (1x1 CONV) \"\"\"\n",
    "        # TODO : try with original ordering\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        shp = [int(y) for y in x.size()]\n",
    "        out = self.lin_a(x.contiguous().view(shp[0]*shp[1]*shp[2], shp[3]))\n",
    "        shp[-1] = self.dim_out\n",
    "        out = out.view(shp)\n",
    "        return out.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "class down_shifted_conv2d(nn.Module):\n",
    "    def __init__(self, num_filters_in, num_filters_out, filter_size=(2,3), stride=(1,1), \n",
    "                    shift_output_down=False, norm='weight_norm'):\n",
    "        super(down_shifted_conv2d, self).__init__()\n",
    "        \n",
    "        assert norm in [None, 'batch_norm', 'weight_norm']\n",
    "        self.conv = nn.Conv2d(num_filters_in, num_filters_out, filter_size, stride)\n",
    "        self.shift_output_down = shift_output_down\n",
    "        self.norm = norm\n",
    "        self.pad  = nn.ZeroPad2d((int((filter_size[1] - 1) / 2), # pad left\n",
    "                                  int((filter_size[1] - 1) / 2), # pad right\n",
    "                                  filter_size[0] - 1,            # pad top\n",
    "                                  0) )                           # pad down\n",
    "        \n",
    "        if norm == 'weight_norm':\n",
    "            self.conv = wn(self.conv)\n",
    "        elif norm == 'batch_norm':\n",
    "            self.bn = nn.BatchNorm2d(num_filters_out)\n",
    "\n",
    "        if shift_output_down :\n",
    "            self.down_shift = lambda x : down_shift(x, pad=nn.ZeroPad2d((0, 0, 1, 0)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x) if self.norm == 'batch_norm' else x\n",
    "        return self.down_shift(x) if self.shift_output_down else x\n",
    "\n",
    "\n",
    "class down_shifted_deconv2d(nn.Module):\n",
    "    def __init__(self, num_filters_in, num_filters_out, filter_size=(2,3), stride=(1,1)):\n",
    "        super(down_shifted_deconv2d, self).__init__()\n",
    "        self.deconv = wn(nn.ConvTranspose2d(num_filters_in, num_filters_out, filter_size, stride, \n",
    "                                            output_padding=1))\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        xs = [int(y) for y in x.size()]\n",
    "        return x[:, :, :(xs[2] - self.filter_size[0] + 1), \n",
    "                 int((self.filter_size[1] - 1) / 2):(xs[3] - int((self.filter_size[1] - 1) / 2))]\n",
    "\n",
    "\n",
    "class down_right_shifted_conv2d(nn.Module):\n",
    "    def __init__(self, num_filters_in, num_filters_out, filter_size=(2,2), stride=(1,1), \n",
    "                    shift_output_right=False, norm='weight_norm'):\n",
    "        super(down_right_shifted_conv2d, self).__init__()\n",
    "        \n",
    "        assert norm in [None, 'batch_norm', 'weight_norm']\n",
    "        self.pad = nn.ZeroPad2d((filter_size[1] - 1, 0, filter_size[0] - 1, 0))\n",
    "        self.conv = nn.Conv2d(num_filters_in, num_filters_out, filter_size, stride=stride)\n",
    "        self.shift_output_right = shift_output_right\n",
    "        self.norm = norm\n",
    "\n",
    "        if norm == 'weight_norm':\n",
    "            self.conv = wn(self.conv)\n",
    "        elif norm == 'batch_norm':\n",
    "            self.bn = nn.BatchNorm2d(num_filters_out)\n",
    "\n",
    "        if shift_output_right :\n",
    "            self.right_shift = lambda x : right_shift(x, pad=nn.ZeroPad2d((1, 0, 0, 0)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x) if self.norm == 'batch_norm' else x\n",
    "        return self.right_shift(x) if self.shift_output_right else x\n",
    "\n",
    "\n",
    "class down_right_shifted_deconv2d(nn.Module):\n",
    "    def __init__(self, num_filters_in, num_filters_out, filter_size=(2,2), stride=(1,1), \n",
    "                    shift_output_right=False):\n",
    "        super(down_right_shifted_deconv2d, self).__init__()\n",
    "        self.deconv = wn(nn.ConvTranspose2d(num_filters_in, num_filters_out, filter_size, \n",
    "                                                stride, output_padding=1))\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        xs = [int(y) for y in x.size()]\n",
    "        x = x[:, :, :(xs[2] - self.filter_size[0] + 1):, :(xs[3] - self.filter_size[1] + 1)]\n",
    "        return x\n",
    "\n",
    "\n",
    "'''\n",
    "skip connection parameter : 0 = no skip connection \n",
    "                            1 = skip connection where skip input size === input size\n",
    "                            2 = skip connection where skip input size === 2 * input size\n",
    "'''\n",
    "class gated_resnet(nn.Module):\n",
    "    def __init__(self, num_filters, conv_op, nonlinearity=concat_elu, skip_connection=0):\n",
    "        super(gated_resnet, self).__init__()\n",
    "        self.skip_connection = skip_connection\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.conv_input = conv_op(2 * num_filters, num_filters) # cuz of concat elu\n",
    "        \n",
    "        if skip_connection != 0 : \n",
    "            self.nin_skip = nin(2 * skip_connection * num_filters, num_filters)\n",
    "\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.conv_out = conv_op(2 * num_filters, 2 * num_filters)\n",
    "\n",
    "\n",
    "    def forward(self, og_x, a=None):\n",
    "        x = self.conv_input(self.nonlinearity(og_x))\n",
    "        if a is not None : \n",
    "            x += self.nin_skip(self.nonlinearity(a))\n",
    "        x = self.nonlinearity(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv_out(x)\n",
    "        a, b = torch.chunk(x, 2, dim=1)\n",
    "        c3 = a * F.sigmoid(b)\n",
    "        return og_x + c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNNLayer_up(nn.Module):\n",
    "    def __init__(self, nr_resnet, nr_filters, resnet_nonlinearity):\n",
    "        super(PixelCNNLayer_up, self).__init__()\n",
    "        self.nr_resnet = nr_resnet\n",
    "        # stream from pixels above\n",
    "        self.u_stream = nn.ModuleList([gated_resnet(nr_filters, down_shifted_conv2d, \n",
    "                                        resnet_nonlinearity, skip_connection=0) \n",
    "                                            for _ in range(nr_resnet)])\n",
    "        \n",
    "        # stream from pixels above and to thes left\n",
    "        self.ul_stream = nn.ModuleList([gated_resnet(nr_filters, down_right_shifted_conv2d, \n",
    "                                        resnet_nonlinearity, skip_connection=1) \n",
    "                                            for _ in range(nr_resnet)])\n",
    "\n",
    "    def forward(self, u, ul):\n",
    "        u_list, ul_list = [], []\n",
    "        \n",
    "        for i in range(self.nr_resnet):\n",
    "            u  = self.u_stream[i](u)\n",
    "            ul = self.ul_stream[i](ul, a=u)\n",
    "            u_list  += [u]\n",
    "            ul_list += [ul]\n",
    "\n",
    "        return u_list, ul_list\n",
    "\n",
    "\n",
    "class PixelCNNLayer_down(nn.Module):\n",
    "    def __init__(self, nr_resnet, nr_filters, resnet_nonlinearity):\n",
    "        super(PixelCNNLayer_down, self).__init__()\n",
    "        self.nr_resnet = nr_resnet\n",
    "        # stream from pixels above\n",
    "        self.u_stream  = nn.ModuleList([gated_resnet(nr_filters, down_shifted_conv2d, \n",
    "                                        resnet_nonlinearity, skip_connection=1) \n",
    "                                            for _ in range(nr_resnet)])\n",
    "        \n",
    "        # stream from pixels above and to thes left\n",
    "        self.ul_stream = nn.ModuleList([gated_resnet(nr_filters, down_right_shifted_conv2d, \n",
    "                                        resnet_nonlinearity, skip_connection=2) \n",
    "                                            for _ in range(nr_resnet)])\n",
    "\n",
    "    def forward(self, u, ul, u_list, ul_list):\n",
    "        for i in range(self.nr_resnet):\n",
    "            u  = self.u_stream[i](u, a=u_list.pop())\n",
    "            ul = self.ul_stream[i](ul, a=torch.cat((u, ul_list.pop()), 1))\n",
    "        \n",
    "        return u, ul\n",
    "         \n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, nr_resnet=5, nr_filters=80, nr_logistic_mix=10, \n",
    "                    resnet_nonlinearity='concat_elu', input_channels=3):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        if resnet_nonlinearity == 'concat_elu' : \n",
    "            self.resnet_nonlinearity = lambda x : concat_elu(x)\n",
    "        else : \n",
    "            raise Exception('right now only concat elu is supported as resnet nonlinearity.')\n",
    "\n",
    "        self.nr_filters = nr_filters\n",
    "        self.input_channels = input_channels\n",
    "        self.nr_logistic_mix = nr_logistic_mix\n",
    "        self.right_shift_pad = nn.ZeroPad2d((1, 0, 0, 0))\n",
    "        self.down_shift_pad  = nn.ZeroPad2d((0, 0, 1, 0))\n",
    "\n",
    "        down_nr_resnet = [nr_resnet] + [nr_resnet + 1] * 2\n",
    "        self.down_layers = nn.ModuleList([PixelCNNLayer_down(down_nr_resnet[i], nr_filters, \n",
    "                                                self.resnet_nonlinearity) for i in range(3)])\n",
    "\n",
    "        self.up_layers   = nn.ModuleList([PixelCNNLayer_up(nr_resnet, nr_filters, \n",
    "                                                self.resnet_nonlinearity) for _ in range(3)])\n",
    "\n",
    "        self.downsize_u_stream  = nn.ModuleList([down_shifted_conv2d(nr_filters, nr_filters, \n",
    "                                                    stride=(2,2)) for _ in range(2)])\n",
    "\n",
    "        self.downsize_ul_stream = nn.ModuleList([down_right_shifted_conv2d(nr_filters, \n",
    "                                                    nr_filters, stride=(2,2)) for _ in range(2)])\n",
    "        \n",
    "        self.upsize_u_stream  = nn.ModuleList([down_shifted_deconv2d(nr_filters, nr_filters, \n",
    "                                                    stride=(2,2)) for _ in range(2)])\n",
    "        \n",
    "        self.upsize_ul_stream = nn.ModuleList([down_right_shifted_deconv2d(nr_filters, \n",
    "                                                    nr_filters, stride=(2,2)) for _ in range(2)])\n",
    "        \n",
    "        self.u_init = down_shifted_conv2d(input_channels + 1, nr_filters, filter_size=(2,3), \n",
    "                        shift_output_down=True)\n",
    "\n",
    "        self.ul_init = nn.ModuleList([down_shifted_conv2d(input_channels + 1, nr_filters, \n",
    "                                            filter_size=(1,3), shift_output_down=True), \n",
    "                                       down_right_shifted_conv2d(input_channels + 1, nr_filters, \n",
    "                                            filter_size=(2,1), shift_output_right=True)])\n",
    "    \n",
    "        num_mix = 3 if self.input_channels == 1 else 10\n",
    "        self.nin_out = nin(nr_filters, num_mix * nr_logistic_mix)\n",
    "        self.init_padding = None\n",
    "\n",
    "\n",
    "    def forward(self, x, sample=False):\n",
    "        # similar as done in the tf repo :  \n",
    "        if self.init_padding is None and not sample: \n",
    "            xs = [int(y) for y in x.size()]\n",
    "            padding = Variable(torch.ones(xs[0], 1, xs[2], xs[3]), requires_grad=False)\n",
    "            self.init_padding = padding.cuda() if x.is_cuda else padding\n",
    "        \n",
    "        if sample : \n",
    "            xs = [int(y) for y in x.size()]\n",
    "            padding = Variable(torch.ones(xs[0], 1, xs[2], xs[3]), requires_grad=False)\n",
    "            padding = padding.cuda() if x.is_cuda else padding\n",
    "            x = torch.cat((x, padding), 1)\n",
    "\n",
    "        ###      UP PASS    ###\n",
    "        x = x if sample else torch.cat((x, self.init_padding), 1)\n",
    "        u_list  = [self.u_init(x)]\n",
    "        ul_list = [self.ul_init[0](x) + self.ul_init[1](x)]\n",
    "        for i in range(3):\n",
    "            # resnet block\n",
    "            u_out, ul_out = self.up_layers[i](u_list[-1], ul_list[-1])\n",
    "            u_list  += u_out\n",
    "            ul_list += ul_out\n",
    "\n",
    "            if i != 2: \n",
    "                # downscale (only twice)\n",
    "                u_list  += [self.downsize_u_stream[i](u_list[-1])]\n",
    "                ul_list += [self.downsize_ul_stream[i](ul_list[-1])]\n",
    "\n",
    "        ###    DOWN PASS    ###\n",
    "        u  = u_list.pop()\n",
    "        ul = ul_list.pop()\n",
    "        \n",
    "        for i in range(3):\n",
    "            # resnet block\n",
    "            u, ul = self.down_layers[i](u, ul, u_list, ul_list)\n",
    "\n",
    "            # upscale (only twice)\n",
    "            if i != 2 :\n",
    "                u  = self.upsize_u_stream[i](u)\n",
    "                ul = self.upsize_ul_stream[i](ul)\n",
    "\n",
    "        x_out = self.nin_out(F.elu(ul))\n",
    "\n",
    "        assert len(u_list) == len(ul_list) == 0, pdb.set_trace()\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f11e7a",
   "metadata": {},
   "source": [
    "*Load the weights of a CIFAR-10 pre-trained PixelCNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a6ff29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "# model.load_state_dict(torch.load('/home/cyber/Desktop/Adrian/PixelCNN_pclucas14/pcnn_lr.0.00040_nr-resnet5_nr-filters160_889.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537d2ee",
   "metadata": {},
   "source": [
    "### Train PixelCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "lr = 0.002\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root=r'/home/cyber/Desktop/Adrian', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95024cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.cross_entropy(input=model(data), target=torch.squeeze(data).long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(model.state_dict(), '/home/cyber/Desktop/Adrian/PixelCNN_Singh_Hrituraj/model.pt')\n",
    "      torch.save(optimizer.state_dict(), '/home/cyber/Desktop/Adrian/PixelCNN_Singh_Hrituraj/optimizer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PixelCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d051781",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc667a",
   "metadata": {},
   "source": [
    "*Training with classifier fit*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cln_pre = np.transpose(x_train_cln, (0, -1, 1, 2))\n",
    "x_train_cln_pre = np.array(x_train_cln_pre, dtype=np.float32)\n",
    "y_train_cln_pre = np.array(y_train_cln, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b85fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cln_pre = np.expand_dims(y_train_cln_pre, axis=2)\n",
    "y_train_cln_pre = np.expand_dims(y_train_cln_pre, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac401968",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cln_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbff9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelcnn.fit(x_train_cln_pre, y_train_cln_pre, 64, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d114b",
   "metadata": {},
   "source": [
    "### Pre-process input for PixelDefend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc25943",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = torch.from_numpy(x_test_adv)\n",
    "adv = adv.transpose(1,-1)\n",
    "adv = adv.numpy()\n",
    "# adv = adv.to('cuda')\n",
    "print(x_test_adv.shape)\n",
    "print(adv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db800730",
   "metadata": {},
   "source": [
    "### Check if GPU is recognised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91f2e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e410c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14971529207878454083\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11697760765792290191\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3127299276\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 297762462080679527\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15711670456020518008\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93760fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53aa9cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdc398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto(device_count = {'GPU': 1})\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34adcb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES = '/device:XLA_GPU:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851233a",
   "metadata": {},
   "source": [
    "### Train and save a model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_cln, y_train_cln, batch_size=64, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a91e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"/home/cyber/dataset_trained_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
